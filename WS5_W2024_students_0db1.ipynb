{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashalem/ML_Human/blob/main/WS5_W2024_students_0db1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<div>Machine Learning and Human Behavior - 236667 - Winter 2024-2025</div>\n",
        "<h1>Workshop #5 - Exploration and Promotion ðŸ¦„</h1>\n",
        "</center>"
      ],
      "metadata": {
        "id": "Lj4TYqYunijM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions and submission guidelines\n",
        "\n",
        "* Clone this notebook and complete the exercise:\n",
        "    * Aim for clear and concise solutions.\n",
        "    * Indicate clearly with a text block the sections of your solutions.\n",
        "    * Answer dry questions in markdown blocks, and wet questions in code blocks.\n",
        "* Submission guidelines:\n",
        "    * Add a text block in the beginning of your notebook with your IDs.\n",
        "    * When you're done, restart the notebook and make sure that everything runs smoothly (Runtime->\"Restart and Run All\")\n",
        "    * Export your notebook as ipynb (File->Download->\"Download .ipynb\")\n",
        "    * If you need to attach additional files to your submission (e.g images), add them to a zip file together with the notebook ipynb file.\n",
        "    * Submit through the course website. Remember to list partner IDs when you submit.\n",
        "* **Due date**: Sunday 02/02/2025, 10:00\n",
        "* For any questions regarding this workshop, contact [Eden](mailto:edens@campus.technion.ac.il)."
      ],
      "metadata": {
        "id": "GZ9lfDp0oCLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In our next workshop, we will continue to explore recommendation system dynamics, and dive into new and interesting recommendation settings.\n",
        "\n",
        "The goal of this homework is to explore one specific recommendation setting that appears in the real world in various forms.\n"
      ],
      "metadata": {
        "id": "SGVc4VStDVzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "l6KSvJztJkqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikit-surprise\n",
        "\n",
        "import itertools\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import IPython.display\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import surprise\n",
        "\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "2986FSjfJmgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workshop 4: Recap"
      ],
      "metadata": {
        "id": "90codp2dEVCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic definitions\n"
      ],
      "metadata": {
        "id": "YX0wtICNIqXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Notations\n",
        "\n",
        "We use the following notations:\n",
        "* Time is assumed to be discrete and denoted by $t\\in\\{0,1,\\dots\\}$\n",
        "* The set of users is denoted by $U$.\n",
        "* The set of \"online users\" requesting recommendation at time $t$ is denoted by $U_t \\subseteq U$.\n",
        "* The set of items is denoted by $X$.\n",
        "* Rating given by user $u\\in U$ to item $x \\in X$ at time $t$ is denoted by $r_t(u,x)\\in[1,5]$. User and item are not explicity specified when they are clear from context.\n",
        "* Predicted ratings are denoted by $\\hat{r}_t (u,x)$.\n",
        "* Recommendations at time $t$ are denoted by $\\{(u,x_u)\\}_{u\\in U_t}$.\n"
      ],
      "metadata": {
        "id": "sTHUnnseLXsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Metrics\n",
        "\n",
        "#### Dynamic metrics\n",
        "* The Average Rating of Recommended Items (*ARRI*) at time $t$ is defined as:\n",
        "$$\n",
        "\\mathrm{ARRI} =\n",
        "\\frac{1}{\\left|U_t\\right|}\n",
        "\\sum_{u\\in U_t}\n",
        "r_t (u, x_u)\n",
        "$$\n",
        "\n",
        "* Rating RMSE at time $t$ is defined as:\n",
        "$$\n",
        "\\mathrm{RMSE} =\n",
        "\\left(\n",
        "\\frac{1}{\\left|U_t\\right|}\n",
        "\\sum_{u\\in U_t}\n",
        "\\left(\n",
        "    \\hat{r}_t (u, x_u) - r_t (u, x_u) \\right)^2\n",
        "\\right)^{0.5}\n",
        "$$\n",
        "\n",
        "#### Aggregate metrics\n",
        "For a given simulation run:\n",
        "* The average ARRI is defined as:\n",
        "$$\n",
        "\\bar{\\mathrm{ARRI}} =\n",
        "\\frac{\n",
        "    \\sum_{t=1}^T\n",
        "    \\sum_{u\\in U_t}\n",
        "    r_t (u, x_u)\n",
        "}{\n",
        "    \\sum_{t=1}^T |U_t|\n",
        "}\n",
        "$$\n",
        "\n",
        "* The average RMSE is defined as:\n",
        "$$\n",
        "\\bar{\\mathrm{RMSE}} = \\left(\n",
        "\\frac{\n",
        "    \\sum_{t=1}^T\n",
        "    \\sum_{u\\in U_t}\n",
        "    \\left(\\hat{r}_t (u, x_u) - r_t (u, x_u) \\right)^2\n",
        "}{\n",
        "    \\sum_{t=1}^T |U_t|\n",
        "}\n",
        "\\right)^{0.5}\n",
        "$$\n",
        "\n",
        "#### Shannon entropy\n",
        "\n",
        "For a given user $u$ being shown $n_u$ items, denote by $R_u=\\left(k_1,\\dots,k_{n_u}\\right)\\in{[K]}^{n_u}$ the list of item topics recommended to the user throughout the simulation run.\n",
        "\n",
        "The [empirical distribution](https://en.wikipedia.org/wiki/Empirical_distribution_function) of topics for user $u$ is denoted by:\n",
        "\n",
        "$$\n",
        "p_u(k) = \\frac{\\text{number of occurrences of $k$ in $R_u$}}{n_u}\n",
        "$$\n",
        "\n",
        "The [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) of a discrete random variable:\n",
        "\n",
        "$$\n",
        "H(p) = -\\sum_k p(k) \\log_2 p(k)\n",
        "$$\n",
        "\n",
        "For a given run, the average entropy across users is:\n",
        "$$\n",
        "\\bar{H} = \\frac{1}{|U|} \\sum_{u\\in U} H(p_u)\n",
        "$$\n"
      ],
      "metadata": {
        "id": "l-Qz_3yFJ7KZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment\n",
        "An *environment* defines the population of users and the collection of available items. It specifies the users' behavior, their preferences and the way they change over time, how the users rate items, etc. In particular, the environments we use here are **stateful**.\n",
        "\n",
        "In this workshop, environments expose the following interface:\n",
        "\n",
        "* `__init__(...)` - Initialize environment using given parameters\n",
        "* `get_initial_ratings()` - Returns a pandas DataFrame with initial ratings $\\{(u_i, x_i, r_i)\\}$. Useful for bootstrapping the recommendation algorithm and avoiding the \"[cold-start](https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)\" problem.\n",
        "* `get_online_users()` - Returns the set of online users $U_t\\subseteq U$ that queried the system at the current time step $t$.\n",
        "* `recommend(recommendations)` - Receives as input a list of tuples $R_t = \\{ (u_i,x_i) \\mid u_i \\in U_t \\} $, where each $u_i \\in U_t$ is an online user, and $x_i$ is the item being recommended. Note that only unseen items can be recommended, and all online users must receive recommendations. The function returns the true ratings given by the users.\n"
      ],
      "metadata": {
        "id": "FDd5vQRWIsKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recommender\n",
        "\n",
        "A *recommender* generates item recommendations to users based on past ratings.\n",
        "\n",
        "In Workshop 4, we recommended the items with the highest predicted rating. Prediction algorithms use the [Surprise](https://surpriselib.com/) framework.\n",
        "\n"
      ],
      "metadata": {
        "id": "tGZO-kFkIvGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulation\n",
        "The simulation works in discrete time steps $t\\in\\{1,2,\\dots\\}$. At each step, only some of the users request a recommendation. We denote these users as *online users*. At time $0$, the recommender also receives initial observations to bootstrap the recommendation algorithm.\n"
      ],
      "metadata": {
        "id": "Wy-4eGaRIwJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environments"
      ],
      "metadata": {
        "id": "TdhVHw1tLphi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `TopicsStatic`\n",
        "\n",
        "(Introduced in HW4)\n",
        "\n",
        "The following environment is based on the `topics-static` environment introduced by [Krauth et. al. 2020](https://arxiv.org/abs/2011.07931).\n",
        "\n",
        "* In the `TopicsStatic` environment, each item is assigned to one of $K$ topics and users prefer certain topics.\n",
        "The preference of user $u$ for items of topic $k$\n",
        "is initialized as $\\pi(u, k) âˆ¼ \\mathrm{Uniform}(0.5, 5.5)$, while the topic\n",
        "$k_x$ of item $x$ is chosen randomly from the set of all topics.\n",
        "\n",
        "* When user $u$ is recommended item $x $ of topic $k_x$, they will rate the item as:\n",
        "$$r_t(u,x) = \\mathrm{clip}_{[1,5]}\\left(\\pi(u, k_x) + z \\right)$$\n",
        "where $z \\sim N(0, \\sigma^2)$ represents exogenous noise not modeled by the simulation, and $\\mathrm{clip}_{[1,5]}$ truncates values to be between $1$ and $5$.\n",
        "* Remark on notations: In this workshop, we slightly adapt notations and denote the Gaussian noise by $z$ of $\\epsilon$ in order to avoid confusion with the $\\varepsilon$-greedy policy discussed in Part 1 of this workshop."
      ],
      "metadata": {
        "id": "rmOqWaQdJpkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `TopicsDynamic`\n",
        "\n",
        "(Introduced in WS4)\n",
        "\n",
        "In `TopicsDynamic`, items are rated in the same way as `TopicsStatic`. In this setting however, user preferences change as a result of content consumption.\n",
        "In particular, if item $x$ is recommended to user $u$ at time $t$, then their preferences are updated as:\n",
        "\n",
        "$$\n",
        "\\pi_{t+1}(u,k)\n",
        "= \\begin{cases}\n",
        "\\mathrm{clip}_{[0.5,5.5]}\\left(\\pi_t(u,k) + a\\right) & k = k_x \\\\\n",
        "\\mathrm{clip}_{[0.5,5.5]}\\left(\\pi_t(u,k) - \\frac{a}{K-1}\\right) & k \\neq k_x\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "where $a$ is a fixed affinity parameter.\n",
        "\n",
        "This environment is based on the `topics-dynamic` environment introduced by [Krauth et. al. 2020](https://arxiv.org/abs/2011.07931).\n",
        "\n",
        "Implementation of the `TopicsDynamic` environment is provided below:"
      ],
      "metadata": {
        "id": "sAd4zO87SxOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Surprise\n",
        "\n",
        "[Surprise](https://surpriselib.com/) is a Python library for building and analyzing recommender systems that deal with explicit rating data.\n",
        "\n",
        "In particular, Surprise provides various ready-to-use prediction algorithms such as baseline algorithms, neighborhood methods, matrix factorization-based, and many others.\n",
        "\n",
        "1. Go over the introduction to Surprise in its [main homepage](https://surpriselib.com/) (\"Overview\", \"Getting started\" sections).\n",
        "2. Go over the \"[Basic usage](https://surprise.readthedocs.io/en/stable/getting_started.html#basic-usage)\" section in the Surprise documentation.\n",
        "3. The `surprise` library is already available in this notebook. (Surprise! ðŸ¥³)\n"
      ],
      "metadata": {
        "id": "l8dee1W2U0T8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code\n",
        "\n",
        "Workshop 5 will use the same infrastructure we used in Workshop 4. The following cell contains the definitions of `TopicsStatic`, `TopicsDynamic`, and `trainset_from_df`. Run it to define the class of environments:"
      ],
      "metadata": {
        "id": "EMut3YE90RWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TopicsStatic:\n",
        "    topic_affinity_params = dict(\n",
        "        low=0.5,\n",
        "        high=5.5,\n",
        "    )\n",
        "    decision_noise_params = dict(\n",
        "        scale=0.5,\n",
        "    )\n",
        "    rating_frequency = 0.2\n",
        "\n",
        "    def __init__(self, n_users, n_items, n_topics, n_initial_ratings, random_state=None):\n",
        "        \"\"\"\n",
        "        Initialize the environment.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_users : int\n",
        "            Number of users in the environment.\n",
        "\n",
        "        n_items : int\n",
        "            Number of items in the environment.\n",
        "\n",
        "        n_topics : int\n",
        "            Number of latent topics in the environment.\n",
        "\n",
        "        n_initial_ratings : int\n",
        "            Number of initial ratings available to the recommender before the\n",
        "            simulation starts.\n",
        "\n",
        "        random_state : int, default=None\n",
        "            Random seed to use, if none is specified, a seed provided by the\n",
        "            OS will be used.\n",
        "        \"\"\"\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        self.all_users = [f'usr_{i}' for i in range(self.n_users)]\n",
        "        self.all_items = [f'itm_{i}' for i in range(self.n_items)]\n",
        "        self.n_topics = n_topics\n",
        "        self.n_initial_ratings = n_initial_ratings\n",
        "        self.rng = np.random.default_rng(random_state)\n",
        "        # Assign topics to items\n",
        "        self._item_topics = self.rng.integers(\n",
        "            low=0,\n",
        "            high=n_topics,\n",
        "            size=n_items\n",
        "        )\n",
        "        # Initialize topics affinity matrix\n",
        "        self._topic_affinity = self.rng.uniform(\n",
        "            **self.topic_affinity_params,\n",
        "            size=(n_users, n_topics),\n",
        "        )\n",
        "        # Initialize environment state\n",
        "        self.t = 0\n",
        "        self.last_online_users = None\n",
        "        self.seen_items = {user_id: list() for user_id in self.all_users}\n",
        "        self.initial_ratings_shown = False\n",
        "\n",
        "    def _get_rating(self, user_id, item_id):\n",
        "        \"\"\"\n",
        "        Calculate rating r_t(user_id, item_id).\n",
        "        \"\"\"\n",
        "        assert item_id not in self.seen_items[user_id], (\n",
        "            'Each item can only be shown once to each user'\n",
        "        )\n",
        "        user_internal_id = self.all_users.index(user_id)\n",
        "        item_internal_id = self.all_items.index(item_id)\n",
        "        self.seen_items[user_id].append(item_id)\n",
        "        item_topic = self._item_topics[item_internal_id]\n",
        "        affinity = self._topic_affinity[user_internal_id, item_topic]\n",
        "        noise = self.rng.normal(**self.decision_noise_params)\n",
        "        rating = np.clip(affinity+noise, 1, 5)\n",
        "        return rating\n",
        "\n",
        "    def _get_latent_topic(self, item_id):\n",
        "        item_internal_id = self.all_items.index(item_id)\n",
        "        return self._item_topics[item_internal_id]\n",
        "\n",
        "    def get_initial_ratings(self):\n",
        "        \"\"\"\n",
        "        Get initial ratings, to be used when initializing the recommender.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        ratings_df : pandas.DataFrame\n",
        "            DataFrame with columns: user_id, item_id, rating, timestamp.\n",
        "            Timestamp for initial data is set to 0.\n",
        "        \"\"\"\n",
        "        assert not self.initial_ratings_shown, (\n",
        "            'Initial ratings can only be calculated once',\n",
        "        )\n",
        "        all_pairs = list(itertools.product(\n",
        "            self.all_users,\n",
        "            self.all_items,\n",
        "        ))\n",
        "        selected_pairs = self.rng.choice(\n",
        "            a=all_pairs,\n",
        "            size=self.n_initial_ratings,\n",
        "            replace=False,\n",
        "        )\n",
        "        ratings = [\n",
        "            (user_id, item_id, self._get_rating(user_id, item_id))\n",
        "            for user_id, item_id in selected_pairs\n",
        "        ]\n",
        "        self.initial_ratings_shown = True\n",
        "        return pd.DataFrame(\n",
        "            data=ratings,\n",
        "            columns=('user_id','item_id','rating')\n",
        "        ).assign(timestamp=self.t)\n",
        "\n",
        "    def get_online_users(self):\n",
        "        \"\"\"\n",
        "        Returns the set of online users that queried the system at the\n",
        "        current time step.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        online_users: array of user_ids\n",
        "        \"\"\"\n",
        "        assert self.last_online_users is None, (\n",
        "            'Previous batch of online users must get recommendations'\n",
        "        )\n",
        "        n_online = self.rng.binomial(\n",
        "            n=self.n_users,\n",
        "            p=self.rating_frequency,\n",
        "        )\n",
        "        online_users = self.rng.choice(\n",
        "            a=self.all_users,\n",
        "            size=n_online,\n",
        "            replace=False,\n",
        "        )\n",
        "        self.last_online_users = set(online_users)\n",
        "        return online_users\n",
        "\n",
        "    def recommend(self, recommendations):\n",
        "        \"\"\"\n",
        "        Recommend items to users.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        recommendations : list of (user_id, item_id) tuples.\n",
        "            Each (user_id, item_id) tuple corresponds to an item recommended\n",
        "            to an online user. Note that only unseen items can be recommended,\n",
        "            and all online users must receive recommendations.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        ratings_df : pandas.DataFrame\n",
        "            True ratings given by the users.\n",
        "            DataFrame with columns: user_id, item_id, rating, timestamp.\n",
        "            Timestamp for recommendations is >= 1.\n",
        "        \"\"\"\n",
        "        assert self.last_online_users is not None, (\n",
        "            'Online users must be selected by calling get_online_users()'\n",
        "        )\n",
        "        assert len(recommendations)==len(self.last_online_users), (\n",
        "            'Number of recommendations must match number of online users'\n",
        "        )\n",
        "        assert {user_id for user_id, _ in recommendations}==self.last_online_users, (\n",
        "            'Users given recommendations must match online users'\n",
        "        )\n",
        "        assert all(item_id not in self.seen_items[user_id] for user_id, item_id in recommendations), (\n",
        "            'Only unseen items can be recommended'\n",
        "        )\n",
        "        ratings = [\n",
        "            (user_id, item_id, self._get_rating(user_id, item_id))\n",
        "            for user_id, item_id in recommendations\n",
        "        ]\n",
        "        self.last_online_users = None\n",
        "        self.t += 1\n",
        "        return pd.DataFrame(\n",
        "            data=ratings,\n",
        "            columns=('user_id','item_id','rating')\n",
        "        ).assign(timestamp=self.t)\n",
        "\n",
        "    def get_unseen_items(self, user_id):\n",
        "        \"\"\"\n",
        "        Get a list of items that the user didn't see yet.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        user_id : int\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        unseen_items : list of int\n",
        "            ids of unseen items.\n",
        "        \"\"\"\n",
        "        return [\n",
        "            item_id\n",
        "            for item_id in self.all_items\n",
        "            if item_id not in self.seen_items[user_id]\n",
        "        ]\n",
        "\n",
        "\n",
        "class TopicsDynamic(TopicsStatic):\n",
        "    def __init__(self, a, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.a = a\n",
        "\n",
        "    def recommend(self, recommendations):\n",
        "        # Recommend and get ratings\n",
        "        ratings_df = super().recommend(recommendations)\n",
        "        # Update affinity\n",
        "        for row in ratings_df.itertuples():\n",
        "            user_internal_id = self.all_users.index(row.user_id)\n",
        "            item_internal_id = self.all_items.index(row.item_id)\n",
        "\n",
        "            # increase affinity for selected item topic\n",
        "            selected_topic = self._item_topics[item_internal_id]\n",
        "            self._topic_affinity[user_internal_id, selected_topic] += self.a\n",
        "            # decrease affinity for other topics\n",
        "            not_selected = np.arange(self.n_topics) != selected_topic\n",
        "            self._topic_affinity[user_internal_id, not_selected] -= (\n",
        "                self.a / (self.n_topics-1)\n",
        "            )\n",
        "            # clip\n",
        "            self._topic_affinity[user_internal_id] = (\n",
        "                self._topic_affinity[user_internal_id].clip(min=0.5, max=5.5)\n",
        "            )\n",
        "        # Return ratings dataframe\n",
        "        return ratings_df\n",
        "\n",
        "\n",
        "def trainset_from_df(df):\n",
        "    \"\"\"\n",
        "    Convert DataFrame to Surprise training set.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        DataFrame with columns [user_id, item_id, rating]\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    trainset : surprise.Trainset\n",
        "    \"\"\"\n",
        "    dataset = surprise.Dataset.load_from_df(\n",
        "        df=df[['user_id','item_id','rating']],\n",
        "        reader=surprise.Reader(rating_scale=(1,5)),\n",
        "    )\n",
        "    return dataset.build_full_trainset()\n"
      ],
      "metadata": {
        "id": "tBh6jtr70a5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "zfcnSRDFnDne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 1234\n",
        "\n",
        "# TopicsDyamic\n",
        "topics_params = {\n",
        "    'n_users': 100,\n",
        "    'n_items': 200,\n",
        "    'n_topics': 10,\n",
        "    'n_initial_ratings': 2000,\n",
        "    'random_state': RANDOM_STATE,\n",
        "}\n",
        "\n",
        "# surprise.SVD\n",
        "svd_model_params = {\n",
        "    'n_factors': 16,\n",
        "    'random_state': RANDOM_STATE,\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "f41RYqgCnFw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI_fR3njT_DM"
      },
      "source": [
        "# Part 1: The effects of exploration\n",
        "Up until now, the recommendation policy we discussed in the workshop was *greedy*, in the sense that they always recommended items having the highest predicted value. In this section, we will explore other recommendation policies which are not fully greedy, and explore how they effect different performance metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iun0ugMPL-wp"
      },
      "source": [
        "## 1.1 $\\epsilon$-greedy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The $\\epsilon$-greedy algorithm\n",
        "**$\\epsilon$-greedy** is a simple non-greedy recommendation policy. For a given $\\epsilon\\in[0,1]$, the $\\epsilon$-greedy policy recommends the item having the highest predicted score with probability $(1-\\epsilon)$, and an item selected uniformly at random with probabilty $\\epsilon$.\n"
      ],
      "metadata": {
        "id": "4AiUYnNLPV9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EpsilonGreedyPolicy:\n",
        "    def __init__(self, epsilon, random_state):\n",
        "        \"\"\"\n",
        "        Initialize the recommendation algorithm.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        epsilon : float\n",
        "            epsilon parameter for epsilon-greedy recommendation.\n",
        "\n",
        "        random_state : int, default=None\n",
        "            Random seed to use, if none is specified, a seed provided by the\n",
        "            OS will be used.\n",
        "        \"\"\"\n",
        "        self.eps = epsilon\n",
        "        self.rng = np.random.default_rng(random_state)\n",
        "\n",
        "    def choose_items_to_recommend(self, candidate_items):\n",
        "        \"\"\"\n",
        "        Choose item to recommend according to the epsilon-greedy algorithm.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        candidate_items : list of (item_id, predicted_rating) tuples.\n",
        "            Each (item_id, predicted_rating) tuple corresponds to a cadidate\n",
        "            item.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        item_id : int\n",
        "            id of recommended item\n",
        "        \"\"\"\n",
        "        if self.rng.random() > self.eps:\n",
        "            # Greedy recommendation\n",
        "            return max(candidate_items, key=lambda t: t[1])[0]\n",
        "        else:\n",
        "            # Recommend uniformly at random\n",
        "            return self.rng.choice(list(candidate_items))[0]\n"
      ],
      "metadata": {
        "id": "737BJFitJZ7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For your convenience, we provide simulation code:"
      ],
      "metadata": {
        "id": "di3xDI7Su7QA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_recommendation_policy(env, cf_model, recommendation_policy, retraining_interval, num_steps):\n",
        "    \"\"\"\n",
        "    Simulate recommendations policy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    env : TopicsStatic (or an instance of one of its subclasses)\n",
        "\n",
        "    cf_model : surprise.AlgoBase\n",
        "\n",
        "    recommendation_policy : EpsilonGreedyPolicy\n",
        "\n",
        "    retraining_interval : int\n",
        "        Retrain the prediction model every `retraining_interval` steps.\n",
        "\n",
        "    num_steps : int\n",
        "        Length of simulation.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    recommendations_df : pandas.DataFrame\n",
        "        pandas DataFrame with all recommendations. Each row represents a\n",
        "        recommendation. Each recommendation is associated with a timestamp,\n",
        "        user id, item id, predicted rating, actual rating, and latent topic.\n",
        "    \"\"\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Train CF model\n",
        "    results = [env.get_initial_ratings()]\n",
        "    cf_model.fit(trainset_from_df(results[0]))\n",
        "\n",
        "    # Simulate dynamics\n",
        "    for t in tqdm(range(num_steps)):\n",
        "        online_users = env.get_online_users()\n",
        "        recommendations = {}\n",
        "        for user_id in online_users:\n",
        "            predicted_ratings = {\n",
        "                item_id: cf_model.predict(user_id, item_id).est\n",
        "                for item_id in env.get_unseen_items(user_id)\n",
        "            }\n",
        "            selected_item = recommendation_policy.choose_items_to_recommend(\n",
        "                candidate_items=predicted_ratings.items()\n",
        "            )\n",
        "            recommendations[(user_id, selected_item)] = predicted_ratings[selected_item]\n",
        "        ratings = env.recommend(list(recommendations))\n",
        "        results.append(\n",
        "            ratings\n",
        "            .assign(\n",
        "                predicted_rating=lambda df: df.apply(\n",
        "                    lambda row: recommendations[(row['user_id'], row['item_id'])],\n",
        "                    axis=1,\n",
        "                ),\n",
        "                latent_topic=lambda df: df['item_id'].map(\n",
        "                    lambda item_id: env._item_topics[env.all_items.index(item_id)]\n",
        "                ),\n",
        "            )\n",
        "        )\n",
        "        if retraining_interval and (t%retraining_interval==0):\n",
        "            cf_model.fit(trainset_from_df(pd.concat(results)))\n",
        "    return pd.concat(results)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "example_results_df = simulate_recommendation_policy(\n",
        "    env=TopicsDynamic(\n",
        "        a=0,\n",
        "        **topics_params\n",
        "    ),\n",
        "    cf_model=surprise.SVD(\n",
        "        **svd_model_params,\n",
        "    ),\n",
        "    recommendation_policy=EpsilonGreedyPolicy(\n",
        "        epsilon=0.1,\n",
        "        random_state=RANDOM_STATE,\n",
        "    ),\n",
        "    retraining_interval=1,\n",
        "    num_steps=20,\n",
        ")\n",
        "\n",
        "example_results_df.sample(5)"
      ],
      "metadata": {
        "id": "P-8Hk-mGu31O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 Simulation\n",
        "For each $\\epsilon \\in \\{0, 0.3, 0.6, 0.9\\}$ use the `simulate_recommendation_policy` function to run a simulation for $\\epsilon$-greedy recommendation. Use the following parameters:\n",
        "* `a=0.0`\n",
        "* 100 time steps\n",
        "* retraining every step (`retraining_interval=1`)\n",
        "* `RANDOM_STATE` variable as the random state for the `EpsilonGreedyPolicy` instance\n",
        "\n",
        "ðŸ”µ **Solution**:"
      ],
      "metadata": {
        "id": "tz1Wz8KnhIQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon_values = [0,0.3,0.6,0.9]\n",
        "num_steps = 100\n",
        "retraining_interval = 1\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "quVUmqWnRKRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.2 Analysis"
      ],
      "metadata": {
        "id": "4EulGJ69-vF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the trade-off between average rating and content diversity?\n",
        "Create a scatter plot illustrating the relations between ARRI and topic entropy:\n",
        "* Each run simulated above will correspond to a single point on the scatter plot.\n",
        "* The x axis of the plot should represent overall ARRI (as defined in the notations section above)\n",
        "* The y axis of the plot should represent topic entropy (shannon entropy of latent topics for each user, averaged across users as in WS4).\n",
        "\n",
        "The different points should be clearly labeled, either using a legend, or using the [`annotate`](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.annotate.html) function. We provide a utility function for your convenience.\n",
        "\n",
        "ðŸ”µ **Solution**:"
      ],
      "metadata": {
        "id": "GBIxyT-ns4GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_scatter_annotated(x,y,labels,xlabel,ylabel,ax=None):\n",
        "    \"\"\"\n",
        "    Utility function - Create a scatter plot with labels for each point\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : np.array\n",
        "        x value of each point\n",
        "\n",
        "    y : np.array\n",
        "        y value of each point\n",
        "\n",
        "    labels : List of string\n",
        "        label of each point\n",
        "\n",
        "    ax : matplotlib.Axes (optional)\n",
        "    \"\"\"\n",
        "    if ax==None:\n",
        "        fig,ax = plt.subplots()\n",
        "    ax.scatter(x,y)\n",
        "    for x_val, y_val, label in zip(x,y,labels):\n",
        "        ax.annotate(label, (x_val, y_val))\n",
        "    ax.set(\n",
        "        xlabel=xlabel,\n",
        "        ylabel=ylabel,\n",
        "    )\n",
        "    return ax\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "ge1bLU7GwDop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain your results:\n",
        "\n",
        "ðŸ”µ **Answer**:\n",
        "\n",
        "(YOUR SOLUTION)"
      ],
      "metadata": {
        "id": "pI-d5I-_zm_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Boredom\n"
      ],
      "metadata": {
        "id": "MYqw5-4NP8q_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### The `TopicsDynamicWithBoredom` environment\n",
        "\n",
        "In the ```TopicsStatic``` environment, a user's $u$ rating for an item $i$ at time $t$ is modeled as:\n",
        "$$r_t(u,x) = \\mathrm{clip}_{[1,5]}\\left(\\pi(u, k_x) + \u000f\\epsilon\\right)$$\n",
        "\n",
        "where $k_x$ is the topic of item $x$, $\\pi$ is the latent affinity function, $\\varepsilon$ is a random gaussian noise, and $clip_{[1,5]}$ turncates the score to be between $1$ and $5$.\n",
        "\n",
        "In this part, you will explore what happens when users get *bored*.\n",
        "Bordeom occurs when users are repeatedly recommended the same topic in a short time span.\n",
        "\n",
        "Following the definitions in [Krauth et. al. 2020](https://arxiv.org/abs/2011.07931), we define an environment with boredom effects, relying on three parameters:\n",
        "* Memory length $m$,\n",
        "* Boredom threshold $\\tau$\n",
        "* Boredom penalty $\\lambda$\n",
        "\n",
        "If a user observes the same topic more than $\\tau$ times within the last $m$ timesteps, their ratings is penalized by $\\lambda$.\n",
        "Specifically:\n",
        "$$r_t(u,x) = \\mathrm{clip}_{[1,5]}\\left(\\pi(u, k_x) - \\lambda I_{m,\\tau}(k_x) + \u000f\\epsilon\\right)$$\n",
        "where\n",
        "$I_{m,\\tau}(k_x)=1$ if topic $k_x$ was observed more than $\\tau$ times within $m$ previous timesteps, and $0$ otherwise.\n",
        "\n",
        "The `TopicsDynamicWithBoredom` inherits from `TopicsDynamic` and implements this environment:"
      ],
      "metadata": {
        "id": "tdDaJ0nl6aLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TopicsDynamicWithBoredom(TopicsDynamic):\n",
        "    def __init__(self, boredom_memory_length, boredom_threshold, boredom_penalty, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.boredom_memory_length = boredom_memory_length\n",
        "        self.boredom_threshold = boredom_threshold\n",
        "        self.boredom_penalty = boredom_penalty\n",
        "\n",
        "    def _get_rating(self, user_id, item_id):\n",
        "        \"\"\"\n",
        "        Calculate rating r_t(user_id, item_id).\n",
        "        \"\"\"\n",
        "        assert item_id not in self.seen_items[user_id], (\n",
        "            'Each item can only be shown once to each user'\n",
        "        )\n",
        "\n",
        "        self.seen_items[user_id].append(item_id)\n",
        "        user_internal_id = self.all_users.index(user_id)\n",
        "        item_internal_id = self.all_items.index(item_id)\n",
        "        item_topic = self._item_topics[item_internal_id]\n",
        "        # Topic affinity\n",
        "        affinity = self._topic_affinity[user_internal_id, item_topic]\n",
        "        # Boredom penalty\n",
        "        last_seen_items = self.seen_items[user_id][-self.boredom_memory_length:]\n",
        "        last_seen_topics = [self._item_topics[self.all_items.index(itm)] for itm in last_seen_items]\n",
        "        last_seen_topic_count = last_seen_topics.count(item_topic)\n",
        "        penalty = self.boredom_penalty*(last_seen_topic_count>=self.boredom_threshold)\n",
        "        # Noise\n",
        "        noise = self.rng.normal(**self.decision_noise_params)\n",
        "        # Final rating\n",
        "        rating = np.clip(affinity-penalty+noise, 1, 5)\n",
        "        return rating\n"
      ],
      "metadata": {
        "id": "vnQhntu-BRfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Simulation\n",
        "Repeat the simulation in exercise 1.1.1 using a `TopicsDynamicWithBoredom` environment with $m = 6$, $\\tau = 4$, and $\\lambda = 3$, with the rest of the parameters remaining the same.\n",
        "\n",
        "Note: The arguments to ```Topics``` corresponding to $m, \\tau, \\lambda$ are ```memory_length, boredom_threshold, boredom_penalty``` respectively.\n",
        "\n",
        "ðŸ”µ **Solution**:"
      ],
      "metadata": {
        "id": "Vk2f2FFhS_PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boredom_environment_params = {\n",
        "    'a': 0.0,\n",
        "    'boredom_memory_length': 6,\n",
        "    'boredom_threshold': 4,\n",
        "    'boredom_penalty': 3,\n",
        "    **topics_params\n",
        "}\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "UKX6wjjoEMsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Analysis\n",
        "\n",
        "Repeat the analysis 1.1.2 for the boredom enviroment, and compare the two sets of results.\n",
        "\n",
        "ðŸ”µ **Solution**:"
      ],
      "metadata": {
        "id": "-TAMdEkhEaxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "sL0K3nru-s2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain your results:\n",
        "\n",
        "ðŸ”µ **Answer**:\n",
        "\n",
        "(YOUR SOLUTION)"
      ],
      "metadata": {
        "id": "h3vhXCMAoV-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Promotion markets\n",
        "\n",
        "In this exercise, we will continue exploring the content supply market and its effect on users.\n"
      ],
      "metadata": {
        "id": "ig28rETAFa9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Homework 5: Recap\n"
      ],
      "metadata": {
        "id": "O12s3SLLHJ04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Setting\n",
        "We will consider the `TopicsStatic` environment (introduced in the previous workshop), in which each item has a topic and users prefer certain topics over others. In this exercise, however, we introduce *suppliers* into the environment. Each supplier owns one topic (so that the number of  suppliers is equal to the number of topics $K$), and profits when users consume items of that topic:\n",
        "Whenever an item from topic $k\\in[K]$ is recommended by the system to some user $u$, supplier $k$ gets paid.\n",
        "\n",
        "The recommendation system allows suppliers to influence recommendations through a *promotion system*: Before each time step, each supplier can place a bid of some amount; the higher the amount supplier $k$ bids, the more likely it is for the system to recommend to users items from topic $k$.\n",
        "\n",
        "More specifically, at each timestep $t$:\n",
        "1. Suppliers $1,\\dots,K$ place bids $b_t^{(1)},\\dots,b_t^{(K)} \\ge 0$ to participate in the promotion process. They can choose how much to bid, but cannot bid more than they currently have.\n",
        "2. The system sorts the suppliers by their bids, and ties are broken lexicographically. Denote the position of topic $k$ in the sorted list by $\\mathrm{pos}_t(k)\\in\\{1,\\dots,K\\}$.\n",
        "3. For each user, the system predicts the ratings of items $\\hat{r}_t(u,x)$, as it is prediction based and\n",
        "recommends the items with the highest predicted ratings.\n",
        "4. For each rating prediction of an item of topic $k$, the system adds a promotion bias $\\beta_k$ to the\n",
        "prediction, where:\n",
        "$$\n",
        "\\beta_t^{(k)}=B\\left(2\\frac{K-\\mathrm{pos}_t(k)}{K-1} - 1\\right)\n",
        "$$\n",
        "This way, the supplier who bid the highest ($\\mathrm{pos}_t(k)=1$) will get a bias of $B$, the supplier who bid the lowest value ($\\mathrm{pos}_t(k)=K$) will get a bias of $-B$, and the supplier who bid the median amount will get a bias of $0$. In our code, we refer to $B$ as the *promotion factor*.\n",
        "5. After calculating the promotion bias terms, the system recommends items according to the modified predictions (original predictions with the added biases):\n",
        "$$\n",
        "x_u = \\mathrm{argmax}_{x\\in X} \\hat{r}_t(u,x) + \\beta_t^{(k_x)}\n",
        "$$\n",
        "\n",
        "6. The supplier of topic $k$ receives $m_t^{(k)}$ dollars, where:\n",
        "$$\n",
        "m_t^{(k)}=100\\frac{\\text{number of items of topic $k$ recommended}}{\\text{number of recommendations in this step}}\n",
        "$$\n",
        "\n",
        "In the beginning of the simulation, all suppliers have $100. To simplify, at each time step, all\n",
        "suppliers bid a random amount of money between 0 and 50% of the money they currently have.\n",
        "\n",
        "\n",
        "\n",
        "After hearing about your outstanding success in Homework 5, your supervisor at the company caught you leaking bidding information to your uncle and fired\n",
        "you. Now you donâ€™t have any access to the recommender or the bids of other suppliers. Try to\n",
        "maximize your uncleâ€™s average income over time by coming up with a bidding strategy using\n",
        "only publicly available information, such as the current budgets of all other suppliers, and the bids\n",
        "and average ratings of the previous time steps (for this you will need to save them in the\n",
        "environment or the recommender).\n",
        "Explain your solution and its underlying rationale."
      ],
      "metadata": {
        "id": "v16IcQ70HY83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Implementation\n"
      ],
      "metadata": {
        "id": "Q2i9BSCNlP-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `BiddingAgent`\n",
        "Suppliers' bidding policies are implemented by subclassing the `BiddingAgent` class:"
      ],
      "metadata": {
        "id": "acQ_2OtE5-n6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiddingAgent:\n",
        "    \"\"\"\n",
        "    Generic class for simulating a bidding agent (supplier)\n",
        "    \"\"\"\n",
        "    def __init__(self, initial_budget, topic_k, random_state=None):\n",
        "        \"\"\"\n",
        "        Initialize the bidding agent.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        initial_budget : float\n",
        "            Initial budget (non-negative)\n",
        "\n",
        "        topic_k : int\n",
        "            Topic id corresponding to the agent (0,...,K-1)\n",
        "\n",
        "        random_state : Seed. Valid input to `np.random.default_rng`.\n",
        "        \"\"\"\n",
        "        assert initial_budget>=0, 'Initial budget must be nonnegative.'\n",
        "        self.initial_budget = initial_budget\n",
        "        self._remaining_budget = initial_budget\n",
        "        self.topic_k = topic_k\n",
        "        self.rng = np.random.default_rng(random_state)\n",
        "        self.payment_history = []\n",
        "        self.global_context = {}\n",
        "\n",
        "    def calculate_bid(self, context=None):\n",
        "        \"\"\"\n",
        "        Return the raw bid, to be implemented by subclasses.\n",
        "        The `place_bid` function validates the value returned.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        context : any\n",
        "            a context parameter for informed decision-making.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        bid : float\n",
        "            bid for next promotion.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def remaining_budget(self):\n",
        "        \"\"\"\n",
        "        Get the remaining budget of the bidding agent.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        remaining_budget : float\n",
        "        \"\"\"\n",
        "        return self._remaining_budget\n",
        "\n",
        "    def transfer_funds(self, m):\n",
        "        \"\"\"\n",
        "        Transfer/receive funds resulting from recommendations.\n",
        "        Negative value of `m` represents tranfer of funds from the agent\n",
        "        to the system, and a positive value of `m` represents a payment\n",
        "        from the system to the agent.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        m : float\n",
        "            Amount of pay.\n",
        "        \"\"\"\n",
        "        assert self._remaining_budget+m>=0, (\n",
        "            'Each payment must preserve a non-negative budget'\n",
        "        )\n",
        "        self._remaining_budget += m\n",
        "        self.payment_history.append(m)\n",
        "\n",
        "    def set_global_context(self, global_context):\n",
        "        \"\"\"\n",
        "        Inform the agent about global simulation parameters, such as their\n",
        "        identity and the items they supply.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        global_context : dict\n",
        "        \"\"\"\n",
        "        self.global_context = global_context\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KHBoJqjXlCnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `RandomFractionBiddingAgent`\n",
        "\n",
        "The `RandomFractionBiddingAgent` class implements the random bidding policy described in the previous section:"
      ],
      "metadata": {
        "id": "h_R-ceTro8nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomFractionBiddingAgent(BiddingAgent):\n",
        "    \"\"\"\n",
        "    Agent simulating a random bidding policy.\n",
        "    At each step, suppliers of this type bid a random amount of money\n",
        "    between 0 and half the money they currently have.\n",
        "    \"\"\"\n",
        "    def calculate_bid(self, context):\n",
        "        return self.rng.uniform(low=0.0,high=0.5)*self.remaining_budget()\n"
      ],
      "metadata": {
        "id": "_Zy0eOJWmrYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `SuppliersGroup`\n",
        "\n",
        "The `SuppliersGroup` describes the collective of bidding agents:"
      ],
      "metadata": {
        "id": "fdMLj88Rp8Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SuppliersGroup:\n",
        "    def __init__(self, agents):\n",
        "        \"\"\"\n",
        "        Initialize the suppliers group.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        agents : list of BiddingAgent\n",
        "        \"\"\"\n",
        "        self.agents = agents\n",
        "\n",
        "    def calculate_bids(self, context):\n",
        "        return [agent.calculate_bid(context) for agent in self.agents]\n",
        "\n",
        "    def transfer_funds(self, payment_vector):\n",
        "        for agent,payment in zip(self.agents, payment_vector):\n",
        "            agent.transfer_funds(payment)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.agents)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.agents)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "        return self.agents[i]\n",
        "\n"
      ],
      "metadata": {
        "id": "D8x1Pz4knDgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simulator\n",
        "\n",
        "The `simulate_recommendations_with_bidding` function runs the simulation. It returns two DataFrames - One with recommendations and responses, and another with budgets and payments."
      ],
      "metadata": {
        "id": "FF39zDkQpUZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_recommendations_with_bidding(\n",
        "    env,\n",
        "    cf_model,\n",
        "    suppliers,\n",
        "    num_steps,\n",
        "    payment_per_step,\n",
        "    promotion_factor,\n",
        "):\n",
        "    \"\"\"\n",
        "    Simulate recommendations with bidding.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    env : TopicsStatic\n",
        "\n",
        "    cf_model : surprise.AlgoBase\n",
        "\n",
        "    num_steps : int\n",
        "        Length of simulation.\n",
        "\n",
        "    payment_per_step : float\n",
        "        Total payment to suppliers per step\n",
        "\n",
        "    promotion_factor : float\n",
        "        Promotion factor B\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    recommendations_df : pandas.DataFrame\n",
        "        pandas DataFrame with all recommendations. Each row represents a\n",
        "        recommendation. Each recommendation is associated with a timestamp,\n",
        "        user id, item id, predicted rating, actual rating, and latent topic.\n",
        "\n",
        "    payments_df : pandas.DataFrame\n",
        "        pandas DataFrame with all payment information. Each row represents\n",
        "        the behavior of a supplier (and its consequences) for a given time\n",
        "        step. Each row is associated with a timestamp, supplier id,\n",
        "        supplier bid, attained position, boost factor, revenue, and\n",
        "        remaining_budget.\n",
        "    \"\"\"\n",
        "    assert isinstance(env, TopicsStatic), (\n",
        "        'env must be an instance of TopicsStatic or one of its subclasses'\n",
        "    )\n",
        "    K = env.n_topics\n",
        "    assert K == len(suppliers), (\n",
        "        'Length of supplier list must match number of topics'\n",
        "    )\n",
        "    recommendation_results = []\n",
        "    payment_results = []\n",
        "\n",
        "    # Inform the suppliers about their identity\n",
        "    for agent in suppliers:\n",
        "        agent.set_global_context(global_context={\n",
        "            'item_ids': [\n",
        "                itm\n",
        "                for i,itm in enumerate(env.all_items)\n",
        "                if env._item_topics[i]==agent.topic_k\n",
        "            ],\n",
        "        })\n",
        "\n",
        "    # Fit initial CF model\n",
        "    recommendation_results = [env.get_initial_ratings()]\n",
        "    cf_model.fit(trainset_from_df(recommendation_results[0]))\n",
        "\n",
        "    # Simulate dynamics\n",
        "    for t in tqdm(range(num_steps)):\n",
        "        online_users = env.get_online_users()\n",
        "        recommendations = {}\n",
        "        # Calculate promotion factors\n",
        "        bids = suppliers.calculate_bids(context={\n",
        "            'online_users': online_users,\n",
        "            'previous_ratings': (\n",
        "                pd.concat(recommendation_results)\n",
        "                .pipe(lambda df: df.drop('latent_topic',axis=1) if t>0 else df)\n",
        "            ),\n",
        "            'previous_bids': pd.DataFrame(payment_results),\n",
        "        })\n",
        "        for agent,bid in zip(suppliers,bids):\n",
        "            assert bid>=0, 'Bids must be positive'\n",
        "            agent.transfer_funds(-bid)\n",
        "        pos = K-(scipy.stats.rankdata(bids, method='ordinal')-1)\n",
        "        beta = promotion_factor*2*((K-pos)/(K-1) - 0.5)\n",
        "        payment = np.zeros(K)\n",
        "\n",
        "        # Recommend\n",
        "        for user_id in online_users:\n",
        "            # Predict ratings\n",
        "            predicted_ratings = {\n",
        "                item_id: cf_model.predict(user_id, item_id).est\n",
        "                for item_id in env.get_unseen_items(user_id)\n",
        "            }\n",
        "            # Add promotion bias\n",
        "            predicted_ratings_with_bias = {\n",
        "                item_id: predicted_rating + beta[env._item_topics[env.all_items.index(item_id)]]\n",
        "                for item_id, predicted_rating\n",
        "                in predicted_ratings.items()\n",
        "            }\n",
        "            selected_item = max(\n",
        "                predicted_ratings_with_bias.items(),\n",
        "                key=lambda t: t[1],\n",
        "            )[0]\n",
        "            recommendations[(user_id, selected_item)] = predicted_ratings[selected_item]\n",
        "            payment[env._item_topics[env.all_items.index(selected_item)]] += payment_per_step/len(online_users)\n",
        "\n",
        "        ratings = env.recommend(list(recommendations))\n",
        "\n",
        "        # Record results\n",
        "        recommendation_results.append(\n",
        "            ratings\n",
        "            .assign(\n",
        "                predicted_rating=lambda df: df.apply(\n",
        "                    lambda row: recommendations[(row['user_id'], row['item_id'])],\n",
        "                    axis=1,\n",
        "                ),\n",
        "                latent_topic=lambda df: df['item_id'].map(\n",
        "                    lambda item_id: env._item_topics[env.all_items.index(item_id)]\n",
        "                ),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Retrain\n",
        "        cf_model.fit(trainset_from_df(pd.concat(recommendation_results)))\n",
        "\n",
        "        # Pay and record remaining budgets\n",
        "        for topic_k,agent in enumerate(suppliers):\n",
        "            agent.transfer_funds(payment[topic_k])\n",
        "            payment_results.append({\n",
        "                'timestamp': t+1,\n",
        "                'supplier': topic_k,  # supplier id\n",
        "                'bid': bids[topic_k],  # supplier bid\n",
        "                'position': pos[topic_k],  # pos_t(k)\n",
        "                'boost': beta[topic_k],  # beta_t^k\n",
        "                'revenue': payment[topic_k],  # payment made to supplier k\n",
        "                'remaining_budget': agent.remaining_budget(),  # remaining budget\n",
        "            })\n",
        "\n",
        "    return (\n",
        "        pd.concat(recommendation_results),  # recommendations_df\n",
        "        pd.DataFrame(payment_results),  # payments_df\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "bNIWRHocmtZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulation parameters\n",
        "\n",
        "The following parameters will be used for simulation:"
      ],
      "metadata": {
        "id": "7Yv7kTpS-2pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_budget = 100\n",
        "bidding_simulation_params = {\n",
        "    'payment_per_step': 100,\n",
        "    'promotion_factor': 3.0,\n",
        "    'num_steps': 100,\n",
        "}"
      ],
      "metadata": {
        "id": "ARSo6lKe-75j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example simulator run\n",
        "\n",
        "The following code is equivalent to the simulation run in Homework 5:"
      ],
      "metadata": {
        "id": "m44c0ndC66y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_bid_recommendation_rng = np.random.default_rng(RANDOM_STATE)\n",
        "\n",
        "(\n",
        "    random_bid_recommendation_results_df,\n",
        "    random_bid_payments_df,\n",
        ") = simulate_recommendations_with_bidding(\n",
        "    # environment\n",
        "    env=TopicsDynamic(\n",
        "        a=0.0,\n",
        "        **topics_params\n",
        "    ),\n",
        "    # prediction model\n",
        "    cf_model=surprise.SVD(\n",
        "        **svd_model_params,\n",
        "    ),\n",
        "    # suppliers\n",
        "    suppliers=SuppliersGroup(\n",
        "        agents=[\n",
        "            RandomFractionBiddingAgent(\n",
        "                initial_budget=initial_budget,\n",
        "                random_state=random_bid_recommendation_rng,\n",
        "                topic_k=k,\n",
        "            )\n",
        "            for k in range(topics_params['n_topics'])\n",
        "        ]\n",
        "    ),\n",
        "    # global simulation parameters (lengts, payment per step, promotion)\n",
        "    **bidding_simulation_params\n",
        ")\n",
        "\n",
        "(\n",
        "    random_bid_payments_df\n",
        "    .pivot(\n",
        "        index='timestamp',\n",
        "        columns='supplier',\n",
        "        values='remaining_budget',\n",
        "    )\n",
        "    .plot.line(\n",
        "        title='Remaining budget over time for different suppliers',\n",
        "        xlabel='Time ($t$)',\n",
        "        ylabel='Remaining budget',\n",
        "        figsize=(12,6),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "yWmLUiQR6-1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Outsider trading\n",
        "\n",
        "After hearing about your stellar success in Homework #5, your supervisor at the company caught you leaking bidding information to your uncle and fired\n",
        "you.\n",
        "\n",
        "Now you donâ€™t have any access to the recommender or the bids of other suppliers. Try to maximize your uncleâ€™s average income over time by coming up with a bidding strategy using only publicly available information, such as the current budgets of all other suppliers, and the bids\n",
        "and ratings from the previous time steps.\n",
        "\n",
        "Implementation details:\n",
        "* Public information is provided through the `context` variable given as argument to `BiddingAgent.calculate_bid`.\n",
        "* In addition, you are informed about the list of items you own through the `BiddingAgent.global_context` dictionary.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6WdjAHkhIQO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PublicInfoBiddingAgent(BiddingAgent):\n",
        "    def calculate_bid(self, context):\n",
        "        # This function should return a positive float representing the\n",
        "        # selected bid.\n",
        "\n",
        "        # online_users is the list of current online users\n",
        "        online_users = context['online_users']\n",
        "\n",
        "        # ratings_df and payments_df are the intermediate values of the\n",
        "        # dataframes returned by the `simulate_recommendations_with_bidding`\n",
        "        # function. (excluding the `latent_topic` column in ratings_df)\n",
        "        ratings_df = context['previous_ratings']\n",
        "        payments_df = context['previous_bids']\n",
        "\n",
        "        # The list of items you owned by this agent is available through\n",
        "        # self.global_context\n",
        "        item_ids = self.global_context['item_ids']\n",
        "\n",
        "        ## YOUR SOLUTION\n"
      ],
      "metadata": {
        "id": "aQ_eLHHdPwwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze the performance of your new bidding heuristic. Simulation code is provided for convenience.\n",
        "\n",
        "ðŸ”µ **Answer**:"
      ],
      "metadata": {
        "id": "G5J0wwuhu5w9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "publicinfo_recommendation_rng = np.random.default_rng(RANDOM_STATE)\n",
        "initial_budget = 100\n",
        "\n",
        "(\n",
        "    publicinfo_recommendation_results_df,\n",
        "    publicinfo_payments_df,\n",
        ") = simulate_recommendations_with_bidding(\n",
        "    # environment\n",
        "    env=TopicsDynamic(\n",
        "        a=0.0,\n",
        "        **topics_params\n",
        "    ),\n",
        "    # prediction model\n",
        "    cf_model=surprise.SVD(\n",
        "        **svd_model_params,\n",
        "    ),\n",
        "    # suppliers\n",
        "    suppliers=SuppliersGroup(\n",
        "        agents=(  # One PublicInfoBiddingAgent and K-1 random bidding agents\n",
        "            [\n",
        "                PublicInfoBiddingAgent(\n",
        "                    initial_budget=300,\n",
        "                    random_state=publicinfo_recommendation_rng,\n",
        "                    topic_k=0,\n",
        "                )\n",
        "            ] + [\n",
        "                RandomFractionBiddingAgent(\n",
        "                    initial_budget=initial_budget,\n",
        "                    random_state=publicinfo_recommendation_rng,\n",
        "                    topic_k=k,\n",
        "                )\n",
        "                for k in range(1,topics_params['n_topics'])\n",
        "            ]\n",
        "        )\n",
        "    ),\n",
        "    # global simulation parameters (lengts, payment per step, promotion)\n",
        "    **bidding_simulation_params\n",
        ")\n"
      ],
      "metadata": {
        "id": "ssKXxxPbPufz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”µ **Analysis**:"
      ],
      "metadata": {
        "id": "3mUisH2pOKaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "8htNbWash7wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain your solution and its underlying rationale. Support your claims with the appropriate data and plots.\n",
        "\n",
        "ðŸ”µ **Answer**:\n",
        "\n",
        "(YOUR SOLUTION)"
      ],
      "metadata": {
        "id": "KVAMrid8vnGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 A prisoner's dilemma?\n",
        "\n",
        "Jealous of your ability to overcome challenging obstacles, your cousin decides to take the bidding agent that you just built and publish its code online!\n",
        "As a result, all other suppliers start using the code you just built, undermining your competitive advantage.\n",
        "\n",
        "Run the same simulation as above, but having all the suppliers use the `PublicInfoBiddingAgent` you implemented above.\n",
        "\n",
        "ðŸ”µ **Answer**:"
      ],
      "metadata": {
        "id": "FZbjGsPeNdgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION\n"
      ],
      "metadata": {
        "id": "SvnmS_PPza-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does this behavior compare to the results of 2.1 and the results obtained in the homework?\n",
        "\n",
        "Discuss the results. In particular, calculate and relate to the following:\n",
        "* ARRI\n",
        "* Content diversity across users and across time\n",
        "* Total revenue of the system\n",
        "* Average total revenue of each supplier\n",
        "* Variance in total revenue across suppliers\n",
        "\n",
        "ðŸ”µ **Answer**:"
      ],
      "metadata": {
        "id": "1Pj78g4k2qzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "E1TPQdKV-fz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”µ **Explain your results**:\n",
        "\n",
        "(YOUR SOLUTION)"
      ],
      "metadata": {
        "id": "InuyPMBjB-TN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "What do you conclude about the dynamics? Why should bidders be encouraged to openly disclose their strategies? Why should they be encouraged to keep them secret?\n",
        "\n",
        "ðŸ”µ **Answer**:\n",
        "\n",
        "(YOUR SOLUTION)"
      ],
      "metadata": {
        "id": "DeXuTO4SCiuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Open-ended question: Designing promotion markets\n",
        "\n",
        "Following the humiliating experience with your cousin, your old boss offers you the opportunity to design a new generation of content promotion systems after you promise not to engage in any more insider trading.\n",
        "\n",
        "You are now the chief designer of *Promotion System 2.0â„¢ï¸*!\n",
        "\n",
        "More formally, your job is to design a new promotion bias rule $\\beta^{(k)}_t$ and a new payment rule $m^{(k)}_t$ (corresponding to the formal description in the \"Setting\" section above) that will achieve better societal outcomes.\n",
        "\n",
        "Desired properties of promotion systems:\n",
        "* Monotonicity with respect to bids - Increasing a bid increases the expected payment at the end of the round.\n",
        "* User satisfaction - Measured in ARRI and/or content diversity.\n",
        "* System revenue - The amount of money collected by the system throughout its run.\n",
        "\n",
        "Your goal is to try to design a promotion rule that improves upon one of these factors without hurting the others. This can mean new functional forms for $\\beta^{(k)}_t$ and $m^{(k)}_t$, or just a change of parameters. In any case, answers should be properly supported.\n",
        "\n"
      ],
      "metadata": {
        "id": "arR8OFNdOxVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.3.1 Plan\n",
        "\n",
        "Before you implement, explain your ideas and the rationale behind them. Why do you expect them to work?\n",
        "\n",
        "ðŸ”µ **Answer**:\n",
        "\n",
        "(YOUR SOLUTION)\n",
        "\n"
      ],
      "metadata": {
        "id": "Pi6C7DsrJliV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2 Implement\n",
        "\n",
        "Implement the new promotion system by creating a modified version of the `simulate_recommendations_with_bidding` function.\n",
        "\n",
        "ðŸ”µ **Answer**:"
      ],
      "metadata": {
        "id": "wB03f_VPJkMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "jrblDlGqKCbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.3 Evaluate\n",
        "Test the new implementation in two settings:\n",
        "1. Homogeneous collection of `PublicInfoBiddingAgent` instances\n",
        "2. A mixture of `PublicInfoBiddingAgent` and `RandomFractionBiddingAgent` instances\n",
        "\n",
        "ðŸ”µ **Answer**:\n"
      ],
      "metadata": {
        "id": "U8uan3cqJ8DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "uAn5Sv26MAmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do the results compare to the existing promotion mechanism? Support your claims with data.\n",
        "\n",
        "ðŸ”µ **Answer**:"
      ],
      "metadata": {
        "id": "HORNUQdgL-xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "O8bquE-mMZfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(YOUR SOLUTION)"
      ],
      "metadata": {
        "id": "Ob0PWzrQMdUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.4 Conclude\n",
        "\n",
        "Summarize - Who benefits from the promotion mechanism you proposed and how? Is there any party that is worse-off?\n",
        "\n",
        "ðŸ”µ **Answer**:\n",
        "\n",
        "(YOUR SOLUTION)"
      ],
      "metadata": {
        "id": "iRsUPULiMhY-"
      }
    }
  ]
}