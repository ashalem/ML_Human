{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List, Tuple, Dict\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants:\n",
    "\n",
    "FACULTY_NAMES = ['Computer Science', 'Economics', 'Psychology', 'Law', 'Art']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FacultyParams:\n",
    "    \"\"\"Parameters for each faculty\"\"\"\n",
    "    name: str\n",
    "    utility_vector: np.ndarray  # Hidden vector that determines student success\n",
    "    capacity: int  # Number of spots available (can be infinite)\n",
    "\n",
    "@dataclass\n",
    "class SupplierParams:\n",
    "    \"\"\"Parameters for each preparation supplier\"\"\"\n",
    "    name: str\n",
    "    diff_vector: np.ndarray  # How this supplier modifies student features\n",
    "\n",
    "class UniversityEnvironment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int = 5,  # Number of student features (e.g., math, english, etc.)\n",
    "        n_faculties: int = 5,  # Number of different faculties\n",
    "        n_suppliers: int = 4,  # Number of preparation suppliers\n",
    "        noise_range: Tuple[float, float] = (-5, 5)  # Range for uniform noise\n",
    "    ):\n",
    "        self.n_features = n_features\n",
    "        self.n_faculties = n_faculties\n",
    "        self.n_suppliers = n_suppliers\n",
    "        self.noise_range = noise_range\n",
    "        \n",
    "        # Initialize faculties with random utility vectors\n",
    "        self.faculties = [\n",
    "            FacultyParams(\n",
    "                name=f\"Faculty_{i}\",\n",
    "                utility_vector=np.random.uniform(0, 1, n_features),\n",
    "                capacity=np.inf  # As per description, infinite capacity\n",
    "            )\n",
    "            for i in range(n_faculties)\n",
    "        ]\n",
    "        \n",
    "        # Initialize suppliers with random modification vectors\n",
    "        self.suppliers = [\n",
    "          SupplierParams(\n",
    "              name=f\"Supplier_{i}\",\n",
    "              diff_vector=np.array([\n",
    "                  0.2 if j == idx1 else 0.1 if j == idx2 else 0\n",
    "                  for j in range(n_features)\n",
    "              ]),\n",
    "          )\n",
    "          for i in range(n_suppliers)\n",
    "          for idx1, idx2 in [np.random.choice(n_features, size=2, replace=False)]\n",
    "        ]\n",
    "        \n",
    "        self.past_applicants_df = None\n",
    "        self.current_applicants_df = None\n",
    "\n",
    "    def generate_past_applicants(\n",
    "        self,\n",
    "        n_applicants: int = 1000\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Generate dataset of past applicants with their outcomes\"\"\"\n",
    "        # Generate random feature vectors\n",
    "        features = np.random.normal(0, 1, (n_applicants, self.n_features))\n",
    "        \n",
    "        # Calculate grades for all faculties\n",
    "        grades = np.zeros((n_applicants, self.n_faculties))\n",
    "        # Reshape faculty vectors into (n_faculties, n_features) matrix\n",
    "        faculty_vectors = np.array([f.utility_vector for f in self.faculties])\n",
    "        # Calculate base grades using matrix multiplication\n",
    "        base_grades = np.dot(features, faculty_vectors.T)\n",
    "        # Add uniform noise to all grades at once\n",
    "        noise = np.random.uniform(*self.noise_range, size=(n_applicants, self.n_faculties))\n",
    "        grades = base_grades + noise\n",
    "        \n",
    "        # Create DataFrame\n",
    "        feature_cols = [f\"feature_{i}\" for i in range(self.n_features)]\n",
    "        faculty_grade_cols = [f\"faculty_{i}_grade\" for i in range(self.n_faculties)]\n",
    "        \n",
    "        df = pd.DataFrame(features, columns=feature_cols)\n",
    "        df_grades = pd.DataFrame(grades, columns=faculty_grade_cols)\n",
    "        \n",
    "        # Add best faculty (argmax of grades)\n",
    "        df['assigned_faculty'] = np.argmax(grades, axis=1)\n",
    "        df['final_grade'] = df_grades.max(axis=1)\n",
    "        \n",
    "        self.past_applicants_df = df\n",
    "        return df\n",
    "\n",
    "    def generate_current_applicants(\n",
    "        self,\n",
    "        n_applicants: int = 100\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Generate dataset of current applicants\"\"\"\n",
    "        # Generate random feature vectors\n",
    "        features = np.random.normal(0, 1, (n_applicants, self.n_features))\n",
    "        \n",
    "        # Create DataFrame\n",
    "        feature_cols = [f\"feature_{i}\" for i in range(self.n_features)]\n",
    "        df = pd.DataFrame(features, columns=feature_cols)\n",
    "        \n",
    "        # Add desired faculty (random)\n",
    "        df['desired_faculty'] = np.random.randint(0, self.n_faculties, n_applicants)\n",
    "        \n",
    "        self.current_applicants_df = df\n",
    "        return df\n",
    "\n",
    "    def choose_supplier_for_applicant(\n",
    "        self,\n",
    "        applicant_features: np.ndarray,\n",
    "        desired_faculty: int,\n",
    "        past_data: pd.DataFrame = None\n",
    "    ) -> Tuple[int, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Choose the best supplier for an applicant based on past data and supplier effects.\n",
    "        \n",
    "        Args:\n",
    "            applicant_features: The current features of the applicant\n",
    "            desired_faculty: The faculty index the applicant wants to get into\n",
    "            past_data: Optional past data to train on. If None, uses self.past_applicants_df\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (chosen_supplier_idx, modified_features)\n",
    "        \"\"\"\n",
    "        if past_data is None:\n",
    "            past_data = self.past_applicants_df\n",
    "        \n",
    "        if past_data is None:\n",
    "            raise ValueError(\"No past data available. Generate past applicants first.\")\n",
    "        \n",
    "        # Create and train applicant's MLP model\n",
    "        feature_cols = [f\"feature_{i}\" for i in range(self.n_features)]\n",
    "        X_train = torch.FloatTensor(past_data[feature_cols].values)\n",
    "        y_train = torch.LongTensor(past_data['assigned_faculty'].values)\n",
    "        \n",
    "        model = ApplicantMLP(self.n_features, self.n_faculties)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "        \n",
    "        # Train the model\n",
    "        model.train()\n",
    "        for epoch in range(100):  # Quick training, adjust epochs as needed\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluate each supplier's effect\n",
    "        model.eval()\n",
    "        best_probability = -1\n",
    "        best_supplier_idx = -1\n",
    "        best_modified_features = None\n",
    "        \n",
    "        original_features = torch.FloatTensor(applicant_features).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Try each supplier\n",
    "            for i, supplier in enumerate(self.suppliers):\n",
    "                # Apply supplier's modification\n",
    "                modified_features = original_features + torch.FloatTensor(supplier.diff_vector)\n",
    "                \n",
    "                # Get probability distribution over faculties\n",
    "                probabilities = model(modified_features)\n",
    "                \n",
    "                # Check probability for desired faculty\n",
    "                prob_desired = probabilities[0, int(desired_faculty)].item()\n",
    "                \n",
    "                if prob_desired > best_probability:\n",
    "                    best_probability = prob_desired\n",
    "                    best_supplier_idx = i\n",
    "                    best_modified_features = modified_features.squeeze(0).numpy()\n",
    "        \n",
    "        if best_supplier_idx == -1:\n",
    "            # If no supplier improves probability, return original features with no supplier\n",
    "            return (-1, applicant_features)\n",
    "        \n",
    "        return (best_supplier_idx, best_modified_features)\n",
    "        \n",
    "    def recommend(\n",
    "        self,\n",
    "        student_features: np.ndarray,\n",
    "        recommended_faculties: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Calculate final grades for students given their features and recommended faculties\n",
    "        \n",
    "        Args:\n",
    "            student_features: Features matrix of shape (n_students, n_features)\n",
    "            recommended_faculties: Array of faculty indices of shape (n_students,)\n",
    "            \n",
    "        Returns:\n",
    "            Array of final grades of shape (n_students,)\n",
    "        \"\"\"\n",
    "        # Get utility vectors for all recommended faculties\n",
    "        faculty_vectors = np.array([self.faculties[f].utility_vector for f in recommended_faculties])\n",
    "        \n",
    "        # Calculate base grades using batch matrix multiplication\n",
    "        base_grades = np.sum(student_features * faculty_vectors, axis=1)\n",
    "        \n",
    "        # Generate noise for all students at once\n",
    "        noise = np.random.uniform(*self.noise_range, size=len(student_features))\n",
    "        \n",
    "        return base_grades + noise\n",
    "\n",
    "    def university_decision_process(\n",
    "        self,\n",
    "        current_applicants_features: np.ndarray,\n",
    "        past_data: pd.DataFrame = None\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "        \"\"\"\n",
    "        Train university model on past data and make faculty recommendations for current applicants.\n",
    "        \n",
    "        Args:\n",
    "            current_applicants_features: Modified features of current applicants (n_applicants x n_features)\n",
    "            past_data: Optional past data to train on. If None, uses self.past_applicants_df\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (chosen_faculties, final_grades, mean_grade)\n",
    "            - chosen_faculties: Array of faculty indices chosen for each applicant\n",
    "            - final_grades: Array of final grades received by each applicant\n",
    "            - mean_grade: Average grade across all applicants\n",
    "        \"\"\"\n",
    "        if past_data is None:\n",
    "            past_data = self.past_applicants_df\n",
    "        \n",
    "        if past_data is None:\n",
    "            raise ValueError(\"No past data available. Generate past applicants first.\")\n",
    "        \n",
    "        # Prepare training data \n",
    "        feature_cols = [f\"feature_{i}\" for i in range(self.n_features)]\n",
    "        \n",
    "        X_train = torch.FloatTensor(past_data[feature_cols].values)\n",
    "        y_train = torch.FloatTensor(past_data['final_grade'].values)\n",
    "        faculty_train = torch.LongTensor(past_data['assigned_faculty'].values)\n",
    "        \n",
    "        # Create and train university model\n",
    "        model = UniversityMLP(self.n_features, self.n_faculties)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "        \n",
    "        # Train the model\n",
    "        model.train()\n",
    "        for epoch in range(200):  # More epochs for better training\n",
    "            optimizer.zero_grad()\n",
    "            predicted_grades = model(X_train)\n",
    "            loss = criterion(predicted_grades, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Make predictions for current applicants\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            current_features = torch.FloatTensor(current_applicants_features)\n",
    "            predicted_grades = model(current_features)\n",
    "            \n",
    "            # Choose best faculty for each applicant based on predicted grades\n",
    "            chosen_faculties = torch.argmax(predicted_grades, dim=1).numpy()\n",
    "        \n",
    "        # Get actual final grades using recommend function for all applicants at once\n",
    "        final_grades = self.recommend(current_applicants_features, chosen_faculties)\n",
    "        \n",
    "        mean_grade = np.mean(final_grades)\n",
    "        \n",
    "        return chosen_faculties, final_grades, mean_grade\n",
    "\n",
    "class UniversityMLP(nn.Module):\n",
    "    \"\"\"Simple MLP for university decisions\"\"\"\n",
    "    def __init__(self, n_features: int, n_faculties: int):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, n_faculties)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class ApplicantMLP(nn.Module):\n",
    "    \"\"\"MLP for applicant decisions with softmax output\"\"\"\n",
    "    def __init__(self, n_features: int, n_faculties: int):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, n_faculties),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "def run_example():\n",
    "# Create environment\n",
    "    env = UniversityEnvironment()\n",
    "    \n",
    "    # Generate past applicants\n",
    "    past_df = env.generate_past_applicants(1000)\n",
    "    print(\"Past applicants shape:\", past_df.shape)\n",
    "    \n",
    "    # Generate current applicants\n",
    "    current_df = env.generate_current_applicants(100)\n",
    "    print(\"Current applicants shape:\", current_df.shape)\n",
    "    \n",
    "    # Get modified features for all current applicants\n",
    "    feature_cols = [f\"feature_{i}\" for i in range(env.n_features)]\n",
    "    modified_features = []\n",
    "    \n",
    "    for idx in range(len(current_df)):\n",
    "        student_features = current_df.iloc[idx][feature_cols].values\n",
    "        desired_faculty = current_df.iloc[idx]['desired_faculty']\n",
    "        \n",
    "        _, modified_student_features = env.choose_supplier_for_applicant(\n",
    "            student_features,\n",
    "            desired_faculty\n",
    "        )\n",
    "        modified_features.append(modified_student_features)\n",
    "    \n",
    "    modified_features = np.array(modified_features)\n",
    "    \n",
    "    # Run university decision process\n",
    "    chosen_faculties, final_grades, mean_grade = env.university_decision_process(modified_features)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"Mean grade across all applicants: {mean_grade:.2f}\")\n",
    "    \n",
    "    # Print detailed results for first 5 applicants\n",
    "    print(\"\\nDetailed results for first 5 applicants:\")\n",
    "    for i in range(5):\n",
    "        desired_faculty = current_df.iloc[i]['desired_faculty']\n",
    "        print(f\"\\nApplicant {i}:\")\n",
    "        print(f\"Desired faculty: {desired_faculty}\")\n",
    "        print(f\"Assigned faculty: {chosen_faculties[i]}\")\n",
    "        print(f\"Final grade: {final_grades[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past applicants shape: (1000, 7)\n",
      "Current applicants shape: (100, 6)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['faculty_0_grade', 'faculty_1_grade', 'faculty_2_grade'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m, in \u001b[0;36mrun_example\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m modified_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(modified_features)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Run university decision process\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m chosen_faculties, final_grades, mean_grade \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniversity_decision_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodified_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResults:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 225\u001b[0m, in \u001b[0;36mUniversityEnvironment.university_decision_process\u001b[0;34m(self, current_applicants_features, past_data)\u001b[0m\n\u001b[1;32m    222\u001b[0m faculty_grade_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaculty_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_grade\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_faculties)]\n\u001b[1;32m    224\u001b[0m X_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(past_data[feature_cols]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m--> 225\u001b[0m y_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[43mpast_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfaculty_grade_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Create and train university model\u001b[39;00m\n\u001b[1;32m    228\u001b[0m model \u001b[38;5;241m=\u001b[39m UniversityMLP(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_faculties)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs236781-hw2/lib/python3.8/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cs236781-hw2/lib/python3.8/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs236781-hw2/lib/python3.8/site-packages/pandas/core/indexes/base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5937\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['faculty_0_grade', 'faculty_1_grade', 'faculty_2_grade'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "run_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs236781-hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
