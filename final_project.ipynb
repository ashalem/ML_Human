{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List, Tuple, Dict\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UniversityMLP(nn.Module):\n",
    "    \"\"\"Simple MLP for university decisions\"\"\"\n",
    "    def __init__(self, n_features: int, n_faculties: int):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            # Add one-hot encoded faculty to features\n",
    "            nn.Linear(n_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, n_faculties)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class ApplicantMLP(nn.Module):\n",
    "    \"\"\"MLP for applicant decisions with softmax output\"\"\"\n",
    "    def __init__(self, n_features: int, n_faculties: int):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, n_faculties),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FacultyParams:\n",
    "    \"\"\"Parameters for each faculty\"\"\"\n",
    "    name: str\n",
    "    utility_vector: np.ndarray  # Hidden vector that determines student success\n",
    "    capacity: int  # Number of spots available (can be infinite)\n",
    "\n",
    "@dataclass\n",
    "class SupplierParams:\n",
    "    \"\"\"Parameters for each preparation supplier\"\"\"\n",
    "    name: str\n",
    "    diff_vector: np.ndarray  # How this supplier modifies student features\n",
    "\n",
    "class UniversityEnvironment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int = 5,  # Number of student features (e.g., math, english, etc.)\n",
    "        n_faculties: int = 5,  # Number of different faculties\n",
    "        n_suppliers: int = 20,  # Number of preparation suppliers\n",
    "        noise_range: Tuple[float, float] = (0,0)  # Range for uniform noise\n",
    "    ):\n",
    "        self.n_features = n_features\n",
    "        self.n_faculties = n_faculties\n",
    "        self.n_suppliers = n_suppliers\n",
    "        self.noise_range = noise_range\n",
    "        \n",
    "        # Initialize faculties with random utility vectors\n",
    "        # Initialize faculties with normalized random utility vectors\n",
    "        self.faculties = [\n",
    "            FacultyParams(\n",
    "                name=[f\"faculty_{i}\" for i in range(n_features)],  # Using the predefined faculty names\n",
    "                utility_vector=self._create_normalized_vector(n_features),\n",
    "                capacity=np.inf  # As per description, infinite capacity\n",
    "            )\n",
    "            for i in range(n_faculties)\n",
    "        ] \n",
    "        \n",
    "        # Initialize suppliers with random modification vectors\n",
    "        self.suppliers = [\n",
    "          SupplierParams(\n",
    "              name=f\"Supplier_{i}\",\n",
    "              diff_vector=np.array([\n",
    "                  15 if j == idx1 else 5 if j == idx2 else -5 if j == idx3 else 0\n",
    "                  for j in range(n_features)\n",
    "              ]),\n",
    "          )\n",
    "          for i in range(n_suppliers)\n",
    "          for idx1, idx2, idx3 in [np.random.choice(n_features, size=3, replace=False)]\n",
    "        ]\n",
    "        \n",
    "        self.past_applicants_df = None\n",
    "        self.current_applicants_df = None\n",
    "\n",
    "    def _create_normalized_vector(self, size: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Create a normalized random vector of given size.\n",
    "        Normalization ensures ||vector|| = 1\n",
    "        \"\"\"\n",
    "        vector = np.random.uniform(0, 1, size)\n",
    "        # Normalize the vector to unit length\n",
    "        return vector / np.linalg.norm(vector, ord=1)\n",
    "    \n",
    "    def _generate_truncated_normal_features(self, n_samples: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate features using truncated normal distribution between 55 and 100.\n",
    "        Uses mean at center of range (77.5) and std that makes the distribution fit well in the range.\n",
    "        \"\"\"\n",
    "        # Generate features with uniform distribution between 40 and 100\n",
    "        features = np.random.uniform(40, 100, (n_samples, self.n_features))\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_past_applicants(\n",
    "        self,\n",
    "        n_applicants: int = 1000\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Generate dataset of past applicants with their outcomes\"\"\"\n",
    "        # Generate random feature vectors\n",
    "        features = self._generate_truncated_normal_features(n_applicants)\n",
    "        \n",
    "        # Randomly assign faculty for each applicant\n",
    "        df = pd.DataFrame(features, columns=[f\"feature_{i}\" for i in range(self.n_features)])\n",
    "        df['assigned_faculty'] = np.random.randint(0, self.n_faculties, n_applicants)\n",
    "        \n",
    "        # Calculate grade only for assigned faculty\n",
    "        faculty_vectors = np.array([f.utility_vector for f in self.faculties])\n",
    "        grades = np.zeros(n_applicants)\n",
    "        # Get faculty vectors for each applicant based on their assigned faculty\n",
    "        faculty_vectors_per_applicant = faculty_vectors[df['assigned_faculty']]\n",
    "        \n",
    "        # Calculate base grades using matrix multiplication\n",
    "        base_grades = np.sum(features * faculty_vectors_per_applicant, axis=1)\n",
    "        \n",
    "        # Generate noise for all applicants at once\n",
    "        noise = np.random.uniform(*self.noise_range, size=n_applicants)\n",
    "        \n",
    "        # Calculate final grades\n",
    "        grades = base_grades + noise\n",
    "            \n",
    "        df['final_grade'] = grades\n",
    "        self.past_applicants_df = df\n",
    "        return df\n",
    "\n",
    "    def generate_current_applicants(\n",
    "        self,\n",
    "        n_applicants: int = 100\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Generate dataset of current applicants\"\"\"\n",
    "        # Generate random feature vectors\n",
    "        features = self._generate_truncated_normal_features(n_applicants)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        feature_cols = [f\"feature_{i}\" for i in range(self.n_features)]\n",
    "        df = pd.DataFrame(features, columns=feature_cols)\n",
    "        \n",
    "        # Add desired faculty (random)\n",
    "        df['desired_faculty'] = np.random.randint(0, self.n_faculties, n_applicants)\n",
    "        \n",
    "        self.current_applicants_df = df\n",
    "        return df\n",
    "    \n",
    "    def train_applicant_model(\n",
    "        self,\n",
    "        past_data: pd.DataFrame = None\n",
    "    ) -> ApplicantMLP:\n",
    "        \"\"\"Train applicant model on past data\"\"\"\n",
    "        if past_data is None:\n",
    "            past_data = self.past_applicants_df\n",
    "        \n",
    "        if past_data is None:\n",
    "            raise ValueError(\"No past data available. Generate past applicants first.\")\n",
    "        \n",
    "        # Create and train applicant's MLP model\n",
    "        feature_cols = [f\"feature_{i}\" for i in range(self.n_features)]\n",
    "        X_train = torch.FloatTensor(past_data[feature_cols].values)\n",
    "        y_train = torch.LongTensor(past_data['assigned_faculty'].values)\n",
    "        \n",
    "        model = ApplicantMLP(self.n_features, self.n_faculties)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Reduced learning rate\n",
    "        \n",
    "        # Train the model\n",
    "        model.train()\n",
    "        \n",
    "        for epoch in range(500):  \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "            print(f'loss: {loss.item():.6f} at epoch {epoch} at applicants training')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def choose_supplier_for_applicant(\n",
    "        self,\n",
    "        applicant_features: np.ndarray,\n",
    "        desired_faculty: int,\n",
    "        applicant_model: ApplicantMLP = None\n",
    "    ) -> Tuple[int, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Choose the best supplier for an applicant based on past data and supplier effects.\n",
    "        \n",
    "        Args:\n",
    "            applicant_features: The current features of the applicant\n",
    "            desired_faculty: The faculty index the applicant wants to get into\n",
    "            past_data: Optional past data to train on. If None, uses self.past_applicants_df\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (chosen_supplier_idx, modified_features)\n",
    "        \"\"\"\n",
    "        # Evaluate each supplier's effect\n",
    "        applicant_model.eval()\n",
    "        best_probability = -1\n",
    "        best_supplier_idx = -1\n",
    "        best_modified_features = None\n",
    "        \n",
    "        original_features = torch.FloatTensor(applicant_features).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Try each supplier\n",
    "            for i, supplier in enumerate(self.suppliers):\n",
    "                # Apply supplier's modification\n",
    "                modified_features_unclipped = original_features + torch.FloatTensor(supplier.diff_vector)\n",
    "                modified_features = np.clip(modified_features_unclipped, 40, 100)\n",
    "                \n",
    "                # Get probability distribution over faculties\n",
    "                probabilities = applicant_model(modified_features)\n",
    "                \n",
    "                # Check probability for desired faculty\n",
    "                prob_desired = probabilities[0, int(desired_faculty)].item()\n",
    "                \n",
    "                if prob_desired > best_probability:\n",
    "                    best_probability = prob_desired\n",
    "                    best_supplier_idx = i\n",
    "                    best_modified_features = modified_features.squeeze(0).numpy()\n",
    "        \n",
    "        if best_supplier_idx == -1:\n",
    "            # If no supplier improves probability, return original features with no supplier\n",
    "            return (-1, applicant_features)\n",
    "        \n",
    "        return (best_supplier_idx, best_modified_features)\n",
    "        \n",
    "    def recommend(\n",
    "        self,\n",
    "        student_features: np.ndarray,\n",
    "        recommended_faculties: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Calculate final grades for students given their features and recommended faculties\n",
    "        \n",
    "        Args:\n",
    "            student_features: Features matrix of shape (n_students, n_features)\n",
    "            recommended_faculties: Array of faculty indices of shape (n_students,)\n",
    "            \n",
    "        Returns:\n",
    "            Array of final grades of shape (n_students,)\n",
    "        \"\"\"\n",
    "        # Get utility vectors for all recommended faculties\n",
    "        faculty_vectors = np.array([self.faculties[f].utility_vector for f in recommended_faculties])\n",
    "        \n",
    "        print(f'faculty_vectors: {faculty_vectors}')\n",
    "        print(f'student_features: {student_features}')\n",
    "        \n",
    "        # Calculate base grades using batch matrix multiplication\n",
    "        base_grades = np.sum(student_features * faculty_vectors, axis=1)\n",
    "        \n",
    "        # Generate noise for all students at once\n",
    "        noise = np.random.uniform(*self.noise_range, size=len(student_features))\n",
    "        \n",
    "        return base_grades + noise\n",
    "\n",
    "    def train_university_model(\n",
    "        self,\n",
    "        past_data: pd.DataFrame = None\n",
    "    ) -> UniversityMLP:\n",
    "        \"\"\"\n",
    "        Train university model on past data.\n",
    "        \n",
    "        Args:\n",
    "            past_data: Optional past data to train on. If None, uses self.past_applicants_df\n",
    "        \n",
    "        Returns:\n",
    "            Trained UniversityMLP model\n",
    "        \"\"\"\n",
    "        if past_data is None:\n",
    "            past_data = self.past_applicants_df\n",
    "        \n",
    "        if past_data is None:\n",
    "            raise ValueError(\"No past data available. Generate past applicants first.\")\n",
    "        \n",
    "        # Prepare training data\n",
    "        feature_cols = [f\"feature_{i}\" for i in range(self.n_features)]\n",
    "        X_train = torch.FloatTensor(past_data[feature_cols].values)\n",
    "        \n",
    "        # Create and train university model\n",
    "        model = UniversityMLP(self.n_features, self.n_faculties)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "        # Custom loss function that only considers the assigned faculty's grade\n",
    "        def custom_loss(predictions, targets, assigned_faculties):\n",
    "            batch_size = predictions.size(0)\n",
    "            indices = torch.arange(batch_size)\n",
    "            predicted_assigned_grades = predictions[indices, assigned_faculties]\n",
    "            return torch.mean((predicted_assigned_grades - targets) ** 2)\n",
    "        \n",
    "        # Train the model\n",
    "        model.train()\n",
    "        batch_size = 128\n",
    "        n_epochs = 100\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            # Process in batches\n",
    "            permutation = torch.randperm(len(X_train))\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                indices = permutation[i:i + batch_size]\n",
    "                batch_x = X_train[indices]\n",
    "                batch_y = torch.FloatTensor(past_data['final_grade'].values[indices])\n",
    "                batch_assigned = torch.LongTensor(past_data['assigned_faculty'].values[indices])\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(batch_x)\n",
    "                loss = custom_loss(predictions, batch_y, batch_assigned)\n",
    "                print(f'loss: {loss} at epoch {epoch}')\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def assign_applicants_to_faculties(\n",
    "        self,\n",
    "        model: UniversityMLP,\n",
    "        current_applicants_features: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "        \"\"\"\n",
    "        Use trained model to make faculty recommendations for current applicants.\n",
    "        \n",
    "        Args:\n",
    "            model: Trained UniversityMLP model\n",
    "            current_applicants_features: Modified features of current applicants (n_applicants x n_features)\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (chosen_faculties, final_grades, mean_grade)\n",
    "            - chosen_faculties: Array of faculty indices chosen for each applicant\n",
    "            - final_grades: Array of final grades received by each applicant\n",
    "            - mean_grade: Average grade across all applicants\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            current_features = torch.FloatTensor(current_applicants_features)\n",
    "            predicted_grades = model(current_features)\n",
    "            \n",
    "            # Choose best faculty for each applicant based on predicted grades\n",
    "            chosen_faculties = torch.argmax(predicted_grades, dim=1).numpy()\n",
    "        \n",
    "        return chosen_faculties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_example():\n",
    "    # Create environment\n",
    "    env = UniversityEnvironment()\n",
    "    \n",
    "    # Generate past applicants\n",
    "    past_df = env.generate_past_applicants(1000)\n",
    "    print(\"Past applicants shape:\", past_df.shape)\n",
    "    \n",
    "    # Generate current applicants\n",
    "    current_df = env.generate_current_applicants(100)\n",
    "    print(\"Current applicants shape:\", current_df.shape)\n",
    "    print(f'current_df: {current_df}')\n",
    "    \n",
    "    # Get modified features for all current applicants\n",
    "    feature_cols = [f\"feature_{i}\" for i in range(env.n_features)]\n",
    "    modified_features = []\n",
    "    original_features = current_df[feature_cols].values\n",
    "    \n",
    "    for idx in range(len(current_df)):\n",
    "        student_features = current_df.iloc[idx][feature_cols].values\n",
    "        desired_faculty = current_df.iloc[idx]['desired_faculty']\n",
    "        \n",
    "        _, modified_student_features = env.choose_supplier_for_applicant(\n",
    "            student_features,\n",
    "            desired_faculty\n",
    "        )\n",
    "        modified_features.append(modified_student_features)\n",
    "    \n",
    "    modified_features = np.array(modified_features)\n",
    "    \n",
    "    # Train university model\n",
    "    trained_model = env.train_university_model(past_df)\n",
    "    \n",
    "    # Make predictions using trained model\n",
    "    chosen_faculties = env.assign_applicants_to_faculties(\n",
    "        trained_model,\n",
    "        modified_features\n",
    "    )\n",
    "    # Calculate percentage of students accepted into their desired faculty\n",
    "    desired_faculties = current_df['desired_faculty'].values\n",
    "    matches = (chosen_faculties == desired_faculties)\n",
    "    acceptance_rate = (np.sum(matches) / len(desired_faculties)) * 100\n",
    "    \n",
    "    # Calculate final grades using original features\n",
    "    final_grades = env.recommend(original_features, chosen_faculties)\n",
    "    mean_grade = np.mean(final_grades)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"Mean grade across all applicants: {mean_grade:.2f}\")\n",
    "    print(f\"\\nPercentage of students accepted to desired faculty: {acceptance_rate:.2f}%\")\n",
    "\n",
    "    \n",
    "    # Print detailed results for first 5 applicants\n",
    "    print(\"\\nDetailed results for first 5 applicants:\")\n",
    "    for i in range(5):\n",
    "        desired_faculty = current_df.iloc[i]['desired_faculty']\n",
    "        print(f\"\\nApplicant {i}:\")\n",
    "        print(f\"Desired faculty: {desired_faculty}\")\n",
    "        print(f\"Assigned faculty: {chosen_faculties[i]}\")\n",
    "        print(f\"Final grade: {final_grades[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_desired_faculty_stats(assigned_faculties, desired_faculties):\n",
    "        total_students = len(desired_faculties)\n",
    "        matches = sum(assigned == desired for assigned, desired in zip(assigned_faculties, desired_faculties))\n",
    "        percentage = (matches / total_students) * 100\n",
    "        return matches, percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_iteration_example():\n",
    "    # Create environment\n",
    "    env = UniversityEnvironment()\n",
    "    feature_cols = [f\"feature_{i}\" for i in range(env.n_features)]\n",
    "    \n",
    "    # Iteration -1: Initial University Training\n",
    "    print(\"\\n=== Iteration -1: Initial University Training ===\")\n",
    "    past_df = env.generate_past_applicants(10000)\n",
    "    trained_model = env.train_university_model(past_df)\n",
    "    \n",
    "    # Generate students that will be used in iterations 0\n",
    "    iteration0_applicants_df = env.generate_current_applicants(10000)\n",
    "    original_features = iteration0_applicants_df[feature_cols].values\n",
    "    \n",
    "    # Iteration 0: Pure Assignment\n",
    "    print(\"\\n=== Iteration 0: Pure Assignment ===\")\n",
    "    # Assign faculties using original features\n",
    "    iteration0_faculties = env.assign_applicants_to_faculties(\n",
    "        trained_model,\n",
    "        original_features\n",
    "    )\n",
    "    \n",
    "    # Get real grades for these assignments\n",
    "    iteration0_grades = env.recommend(original_features, iteration0_faculties)\n",
    "    \n",
    "    # Create training data for students from iteration 0\n",
    "    iteration0_df = pd.DataFrame(original_features, columns=feature_cols)\n",
    "    iteration0_df['assigned_faculty'] = iteration0_faculties\n",
    "    iteration0_df['final_grade'] = iteration0_grades\n",
    "    \n",
    "    # Iteration 1: Student Learning\n",
    "    print(\"\\n=== Iteration 1: Student Learning ===\")\n",
    "    iteration1_applicants_df = env.generate_current_applicants(10000)\n",
    "    modified_features_with_features_knowledge = []\n",
    "    modified_features_without_features_knowledge = []\n",
    "    \n",
    "    applicant_model = env.train_applicant_model(iteration0_df)\n",
    "    \n",
    "    for idx in range(len(iteration1_applicants_df)):\n",
    "        student_features = iteration1_applicants_df.iloc[idx][feature_cols].values\n",
    "        desired_faculty = iteration1_applicants_df.iloc[idx]['desired_faculty']\n",
    "        \n",
    "        # Now students learn from iteration0 data instead of past_df\n",
    "        _, modified_student_features = env.choose_supplier_for_applicant(\n",
    "            student_features,\n",
    "            desired_faculty,\n",
    "            applicant_model\n",
    "        )\n",
    "        modified_features_with_features_knowledge.append(modified_student_features)\n",
    "        _, modified_student_features_without_features_knowledge = env.choose_supplier_for_applicant(\n",
    "            np.zeros_like(student_features),\n",
    "            desired_faculty,\n",
    "            applicant_model\n",
    "        )\n",
    "        modified_student_features_without_features_knowledge = modified_student_features_without_features_knowledge + student_features\n",
    "        modified_features_without_features_knowledge.append(modified_student_features_without_features_knowledge)\n",
    "    \n",
    "    modified_features_with_features_knowledge = np.array(modified_features_with_features_knowledge)\n",
    "    modified_features_without_features_knowledge = np.array(modified_features_without_features_knowledge)\n",
    "    \n",
    "    # Get final assignments and grades using modified features\n",
    "    final_faculties_modified = env.assign_applicants_to_faculties(\n",
    "        trained_model,\n",
    "        modified_features_with_features_knowledge\n",
    "    )\n",
    "    \n",
    "    final_faculties_modified_without_features_knowledge = env.assign_applicants_to_faculties(\n",
    "        trained_model,\n",
    "        modified_features_without_features_knowledge\n",
    "    )\n",
    "    \n",
    "    final_faculties_original = env.assign_applicants_to_faculties(\n",
    "        trained_model,\n",
    "        original_features\n",
    "    )\n",
    "    \n",
    "    # Calculate final grades using original features\n",
    "    final_grades_original = env.recommend(original_features, final_faculties_original)\n",
    "    final_grades_modified = env.recommend(original_features, final_faculties_modified)\n",
    "    final_grades_modified_without_features_knowledge = env.recommend(original_features, final_faculties_modified_without_features_knowledge)\n",
    "    \n",
    "    \n",
    "    # Calculate stats for both iterations\n",
    "    desired_faculties = iteration1_applicants_df['desired_faculty'].values\n",
    "    final_matches_original, final_percentage_original = calculate_desired_faculty_stats(final_faculties_original, desired_faculties)\n",
    "    final_matches_modified, final_percentage_modified = calculate_desired_faculty_stats(final_faculties_modified, desired_faculties)\n",
    "    final_matches_modified_without_features_knowledge, final_percentage_modified_without_features_knowledge = calculate_desired_faculty_stats(final_faculties_modified_without_features_knowledge, desired_faculties)\n",
    "    \n",
    "    # # Print comparison of results\n",
    "    # print(\"\\nResults Comparison:\")\n",
    "    # print(\"\\nIteration 0 (No Gaming):\")\n",
    "    # print(f\"Mean grade: {np.mean(iteration0_grades):.2f}\")\n",
    "    # print(f\"Faculty distribution: {np.bincount(iteration0_faculties)}\")\n",
    "    # print(f\"Students who got desired faculty: {iter0_matches} ({iter0_percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"Mean grade: {np.mean(final_grades_original):.2f}\")\n",
    "    print(f\"Faculty distribution: {np.bincount(final_faculties_original)}\")\n",
    "    print(f\"Students who got desired faculty: {final_matches_original} ({final_percentage_original:.1f}%)\")\n",
    "    print(f\"Mean grade: {np.mean(final_grades_modified):.2f}\")\n",
    "    print(f\"Faculty distribution: {np.bincount(final_faculties_modified)}\")\n",
    "    print(f\"Students who got desired faculty: {final_matches_modified} ({final_percentage_modified:.1f}%)\")\n",
    "    print(f\"Mean grade: {np.mean(final_grades_modified_without_features_knowledge):.2f}\")\n",
    "    print(f\"Faculty distribution: {np.bincount(final_faculties_modified_without_features_knowledge)}\")\n",
    "    print(f\"Students who got desired faculty: {final_matches_modified_without_features_knowledge} ({final_percentage_modified_without_features_knowledge:.1f}%)\")\n",
    "    # Print detailed results for first 5 applicants\n",
    "    # print(\"\\nDetailed results for first 5 applicants:\")\n",
    "    # for i in range(5):\n",
    "    #     desired_faculty = iteration1_applicants_df.iloc[i]['desired_faculty']\n",
    "    #     print(f\"\\nApplicant {i}:\")\n",
    "    #     print(f\"Desired faculty: {desired_faculty}\")\n",
    "    #     print(f\"Iteration 0 faculty: {iteration0_faculties[i]}\")\n",
    "    #     print(f\"Iteration 0 grade: {iteration0_grades[i]:.2f}\")\n",
    "    #     print(f\"Final faculty: {final_faculties[i]}\")\n",
    "    #     print(f\"Final grade: {final_grades[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_multi_iteration_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs236781-hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
