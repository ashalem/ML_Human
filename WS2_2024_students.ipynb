{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashalem/ML_Human/blob/main/WS2_2024_students.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mpd38HztkAh"
      },
      "source": [
        "<div>Machine Learning and Human Behavior - 236667 - Winter 2024-2025</div>\n",
        "<font size=\"6\">Workshop #2 - Discrete Choice ✨</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions and submission guidelines\n",
        "\n",
        "* Clone this notebook and complete the exercise:\n",
        "    * Aim for clear and concise solutions.\n",
        "    * Indicate clearly with a text block the sections of your solutions.\n",
        "    * Answer dry questions in text (markdown) blocks, and wet questions in code blocks.\n",
        "* Submission guidelines:\n",
        "    * When you're done, restart the notebook, and make sure that everything runs smoothly (Runtime->\"Restart and Run All\")\n",
        "    * Add a text block in the beginning of your notebook with your IDs.\n",
        "    * Export your notebook as ipynb (File->Download->\"Download .ipynb\")\n",
        "    * If you need to attach additional files to your submission (e.g images), add them to a zip file together with the notebook ipynb file.\n",
        "    * Submit through the course website. Remember to list partner IDs when you submit.\n",
        "* **Due date**: Sunday 15/12/2024, 10:00\n",
        "* For any questions regarding this workshop task, contact [Lotan](mailto:lotan.amit@campus.technion.ac.il).\n"
      ],
      "metadata": {
        "id": "8flVAj3563K3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWK5QJd7opXM"
      },
      "source": [
        "## Preliminaries\n",
        "Run these cells to load into memory interface objects and functions that will be used throughtout today's workshop.\n",
        "\n",
        "No need to read the actual code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25Ie6znsg1gU"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import abc\n",
        "import string\n",
        "import statsmodels.api as sm\n",
        "import itertools\n",
        "from sklearn import svm, linear_model\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-57rrztworxu",
        "cellView": "form"
      },
      "source": [
        "#@title Context Effects\n",
        "\n",
        "# Generate Choice\n",
        "\n",
        "class UserModel(abc.ABC):\n",
        "  @abc.abstractclassmethod\n",
        "  def __call__(self, X, *args):\n",
        "    '''\n",
        "    Given items X, calculate the user's valuation v(x) for each item x\n",
        "    '''\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def predict(self, X, *args):\n",
        "    raise NotImplementedError()\n",
        "\n",
        "class RationalUserModel(UserModel):\n",
        "\n",
        "  def __init__(self, beta_h):\n",
        "    self.beta_h = beta_h\n",
        "    self.type = \"rational\"\n",
        "\n",
        "  def __call__(self, X):\n",
        "    return X@self.beta_h\n",
        "\n",
        "  def choice(self, X):\n",
        "    return np.argmax(self(X), axis=0)\n",
        "\n",
        "\n",
        "class AttractionUserModel(UserModel):\n",
        "  def __init__(self, beta_h, alpha_attr):\n",
        "    # rational_utility_weights\n",
        "    self.rational_utility_weights = beta_h\n",
        "    # attraction_coefficient\n",
        "    self.attraction_coefficient = alpha_attr\n",
        "    self.name = \"attraction\"\n",
        "\n",
        "  def __call__(self, X):\n",
        "    # X: shape=(num_items,num_features) - Item covariates\n",
        "    return (\n",
        "        self._rational_decision_term(X)\n",
        "        + self.attraction_coefficient*self._attraction_term(X)\n",
        "    )\n",
        "\n",
        "  def _rational_decision_term(self, X):\n",
        "    return X@self.rational_utility_weights\n",
        "\n",
        "  def _attraction_term(self, X):\n",
        "    # Calculate preference vector\n",
        "    preference_vector = X.max(axis=0)-X.min(axis=0)\n",
        "    preference_vector_normalized = (\n",
        "        preference_vector\n",
        "        /np.sqrt(preference_vector@preference_vector)\n",
        "    )\n",
        "    # Calculate dominance and distance matrices\n",
        "    N = len(X)\n",
        "    dominance = np.zeros((N,N))\n",
        "    distance = np.zeros((N,N))\n",
        "    for i in range(N):\n",
        "      for j in range(N):\n",
        "        dominance[i,j] = (+1)*np.all(X[i]-X[j] >= 0) + (-1)*np.all(X[j]-X[i] >= 0)\n",
        "        distance[i,j] = abs(preference_vector_normalized@(X[i]-X[j]))\n",
        "\n",
        "    attraction_terms = (dominance*distance).sum(axis=1)\n",
        "    return attraction_terms\n",
        "\n",
        "  def choice(self, X):\n",
        "    return np.argmax(self(X), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "class SimilarityUserModel(UserModel):\n",
        "\n",
        "  def __init__(self, beta_h, beta_sim):\n",
        "    self.beta_h = beta_h\n",
        "    self.beta_sim = beta_sim\n",
        "    self.name = \"similarity\"\n",
        "\n",
        "  def __call__(self, X):\n",
        "\n",
        "    # calculate actual value\n",
        "    v_ih = X@self.beta_h\n",
        "\n",
        "    # calculate perference vector\n",
        "    pref_vec = X.max(axis=0) - X.min(axis=0)\n",
        "\n",
        "\n",
        "    # project on the ortogonal hyperplane\n",
        "    X_projected = np.zeros(X.shape)\n",
        "    projection_size = np.zeros(X.shape[0])\n",
        "\n",
        "    for i in range(X.shape[0]):\n",
        "        X_projected[i, :] = X[i,:] -  (X[i,:].dot(pref_vec) / np.linalg.norm(pref_vec)) * pref_vec\n",
        "\n",
        "    # find min distance on projected\n",
        "\n",
        "    distances = np.zeros((X_projected.shape[0], X_projected.shape[0]))\n",
        "\n",
        "    for i in range(X_projected.shape[0]): # could be optimized (cal half mat etc..)\n",
        "      for j in range(X_projected.shape[0]):\n",
        "        distances[i,j] = np.linalg.norm(X_projected[i,:] - X_projected[j,:])\n",
        "\n",
        "    # avoide i == j\n",
        "    distances = distances + np.eye(distances.shape[0])*distances.max()\n",
        "\n",
        "    min_distances = distances.min(axis=1) # go over columns\n",
        "\n",
        "    return v_ih + self.beta_sim*min_distances\n",
        "\n",
        "  def choice(self, X):\n",
        "    return np.argmax(self(X))\n",
        "\n",
        "\n",
        "class CompromiseUserModel(UserModel):\n",
        "\n",
        "  def __init__(self, beta_h, beta_com):\n",
        "    self.beta_h = beta_h\n",
        "    self.beta_com = beta_com\n",
        "    self.name = 'compromise'\n",
        "\n",
        "  def __call__(self, X):\n",
        "\n",
        "    # calculate rational value\n",
        "    v_ih = X@self.beta_h\n",
        "    # calculate compromise value\n",
        "    X_com = (X.max(axis=0) + X.min(axis=0)) / 2\n",
        "\n",
        "    # pairwise distance between rows of X and X_com\n",
        "    d_im = np.zeros(X.shape[0])\n",
        "    for i in range(X.shape[0]):\n",
        "        d_im[i] = np.linalg.norm(X[i,:] - X_com)\n",
        "\n",
        "    return v_ih + -d_im*self.beta_com\n",
        "\n",
        "  def x_user_choice_positions(self, X):\n",
        "    return np.argmax(self(X), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Context Environment\n",
        "\n",
        "Counter = 0\n",
        "\n",
        "class DiscreteChoiceEnvironment:\n",
        "    \"\"\"\n",
        "    Generic class for discrete-choice dataset generation\n",
        "    \"\"\"\n",
        "    n_features = 8\n",
        "    observations_per_user = 10\n",
        "    items_per_slate = 1\n",
        "    train_user_proportion = 0.6\n",
        "\n",
        "\n",
        "    def _generate_user_item_attributes(self, n_users):\n",
        "        \"\"\"\n",
        "        Generate latent parameters for users and items.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_users : int\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "        users : ndarray of shape (n_users, n_features)\n",
        "        items : ndarray of shape\n",
        "                (n_users, observations_per_user, items_per_slate, n_features)\n",
        "        \"\"\"\n",
        "        users = np.random.normal(\n",
        "            size=(\n",
        "                n_users,\n",
        "                self.n_features,\n",
        "            ),\n",
        "        )\n",
        "        items = np.random.normal(\n",
        "            size=(\n",
        "                n_users,\n",
        "                self.observations_per_user,\n",
        "                self.items_per_slate,\n",
        "                self.n_features,\n",
        "            ),\n",
        "        )\n",
        "        return users, items\n",
        "\n",
        "    def _choice(self, users, items):\n",
        "        \"\"\"\n",
        "        Discrete choice function\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        users : ndarray of shape (n_users, n_features)\n",
        "        items : ndarray of shape\n",
        "                (n_users, observations_per_user, items_per_slate, n_features)\n",
        "\n",
        "        Output\n",
        "        ------\n",
        "        choice : Dict[str -> ndarray of shape(n_users, observations_per_user)]\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _generate_choice_dataset(self, n_users):\n",
        "        \"\"\"\n",
        "        Generate choice dataset, formatted as pandas dataframe.\n",
        "        \"\"\"\n",
        "        users, items = self._generate_user_item_attributes(n_users)\n",
        "        choice_dct = self._choice(users, items)\n",
        "        rows = []\n",
        "        for i in range(n_users):\n",
        "            for j in range(self.observations_per_user):\n",
        "                dct = {}\n",
        "                dct['user_id'] = f'{i}'\n",
        "                dct['slate_id'] = f'{i}_{j}'\n",
        "                for k in range(self.items_per_slate):\n",
        "                    for l in range(self.n_features):\n",
        "                        dct[f'x_{k},{l}'] = items[i,j,k,l]\n",
        "                for choice_type, choice_matrix in choice_dct.items():\n",
        "                    dct[choice_type] = choice_matrix[i,j]\n",
        "                rows.append(dct)\n",
        "        df = pd.DataFrame(rows)\n",
        "        return df\n",
        "\n",
        "    def generate_datasets(self, n_users):\n",
        "        n_train_users = int(n_users*self.train_user_proportion)\n",
        "        n_test_users = n_users - n_train_users\n",
        "        return (\n",
        "            self._generate_choice_dataset(n_train_users),\n",
        "            self._generate_choice_dataset(n_test_users),\n",
        "        )\n",
        "\n",
        "\n",
        "class ContextChoiceEnvironment(DiscreteChoiceEnvironment):\n",
        "    \"\"\"\n",
        "    Dataset generator for binary choice with decision noise\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 slate_number=3,\n",
        "                 observations_per_user=50,\n",
        "                 num_items_omega=15):\n",
        "\n",
        "        # self.noise_scale = noise_scale\n",
        "        user_model = AttractionUserModel(\n",
        "        beta_h=np.array([1,9]),\n",
        "          alpha_attr=3,\n",
        "      )\n",
        "\n",
        "        self.total_item_count = 0\n",
        "        self.user_model = user_model\n",
        "        self.slate_number = slate_number\n",
        "        self.observations_per_user = observations_per_user\n",
        "        self._generate_ex1_items(slate_number=slate_number,\n",
        "                                 num_items_omega=num_items_omega)\n",
        "        self.Counter = 0\n",
        "\n",
        "\n",
        "    def _generate_ex1_items(self, slate_number=3, num_items_omega=15):\n",
        "      if slate_number == 1:\n",
        "        self.omega = np.array([[1,3,3,4,10,4,2],[1,7.5,5,4,5,6,1]])\n",
        "        self.E_s = np.array([10, 20, 80, 40, 30, 80, 100])\n",
        "        self.omega_tag = np.array([[4,2.5,4.5],[4.5,6,5]])\n",
        "        self.E_s_tag = np.array([5, 8, 3])\n",
        "\n",
        "      elif slate_number == 2:\n",
        "        self.omega = np.array([[3,8,8.5,4,10,8,2, 1],[8,7,4,4,5,6,1, 8]])\n",
        "        self.E_s = np.array([10, 90, 30, 50, 30, 40,100,90])\n",
        "\n",
        "        self.omega_tag = np.array([[4,3,4.5,6],[8,6,5,6]])\n",
        "        self.E_s_tag = np.array([5, 8, 3, 9])\n",
        "\n",
        "      else:\n",
        "        np.random.seed(24)\n",
        "        num_items_omega = 15\n",
        "        self.omega, self.omega_tag = list(), list()\n",
        "        self.E_s, self.E_s_tag = list(), list()\n",
        "\n",
        "        for i in range(self.observations_per_user):\n",
        "          self.omega.append(np.hstack([np.zeros((num_items_omega, 1)),\n",
        "                                        np.ones((num_items_omega, 1))*i,\n",
        "                                        np.random.randint(\n",
        "                                            20,size=(num_items_omega,2)),\n",
        "                                       np.random.randint(\n",
        "                                           20,100,size=(num_items_omega,1))\n",
        "                                        ]\n",
        "                                       )\n",
        "          )\n",
        "\n",
        "          self.omega_tag.append(np.hstack([np.zeros((100, 1)),\n",
        "                              np.ones((100, 1))*i,\n",
        "                              np.random.randint(\n",
        "                                  20,size=(100,2)),\n",
        "                              np.random.randint(20,size=(100,1))\n",
        "                              ]\n",
        "                              )\n",
        "          )\n",
        "\n",
        "        self.omega = np.vstack(self.omega).T\n",
        "        self.omega_tag = np.vstack(self.omega_tag).T\n",
        "        self._items_to_frame(self.omega,self.E_s, data_name=\"Omega\")\n",
        "        self._items_to_frame(self.omega_tag, self.E_s_tag, ord('I'),\n",
        "                                     data_name=\"Omega_tag\")\n",
        "\n",
        "      return\n",
        "\n",
        "    def _items_to_frame(self, omega, E_s, char_start=ord('A'), data_name=\"Omega\"):\n",
        "\n",
        "        data = pd.DataFrame(omega.T).reset_index()\n",
        "        data['index'] += self.total_item_count\n",
        "        self.total_item_count += len(data)\n",
        "        data.rename(columns={'index':'item_id'}, inplace=True)\n",
        "        # data.set_index('item_id', inplace=True)\n",
        "\n",
        "        if len(data) < self.observations_per_user:\n",
        "          data['user_id'] = np.zeros(len(data))\n",
        "          data['slate_id'] = np.zeros(len(data))\n",
        "          data['rational_user_val'] = omega.T@\\\n",
        "                            self.user_model.rational_utility_weights\n",
        "          data[\"E_s\"] = E_s\n",
        "\n",
        "        else:\n",
        "          data['rational_user_val'] = data.loc[:,[2,3]].values@\\\n",
        "                  self.user_model.rational_utility_weights\n",
        "\n",
        "          data.rename(columns={0:'user_id', 1:'slate_id',\n",
        "                               2:'x_0', 3:'x_1', 4:'E_s'},\n",
        "                      inplace=True)\n",
        "\n",
        "        data['name'] = 'itm_' + data['item_id'].astype(str)\n",
        "        # 'N/A' #data['index'].apply(lambda x: chr(char_start+x))\n",
        "\n",
        "        if data_name == \"Omega\":\n",
        "          self.omega_df = data\n",
        "        else:\n",
        "          self.omega_tag_df = data\n",
        "\n",
        "        return data\n",
        "\n",
        "    def generate_slate_data_set(self, slate_id):\n",
        "\n",
        "          # data = self.omega_df.loc[self.omega_df.slate_id == slate_id].reset_index().drop(columns=[\"level_0\"])\n",
        "          # data = self.omega_df.loc[self.omega_df.slate_id == slate_id]\n",
        "          data = self.omega_df.query('slate_id==@slate_id').copy()\n",
        "\n",
        "          # self.top_5 = data.rational_user_val.argsort()[-5:][::-1]\n",
        "          self.top_5 = data.rational_user_val.sort_values(ascending=False).iloc[:5].index\n",
        "          # data['top_5'] = data['index'].apply(lambda x: int(x) in self.top_5.values)\n",
        "          data['perceived_val'] = np.nan\n",
        "          feature_cols = [col for col in data.columns if col.startswith('x')]\n",
        "          data.loc[self.top_5, ['perceived_val']] = self.user_model(\n",
        "              data.loc[self.top_5, feature_cols].values)\n",
        "          data = self._choice(data)\n",
        "\n",
        "          return data\n",
        "\n",
        "\n",
        "    def inspect_data(self, items_type=\"current\", slate_id=-1):\n",
        "      if items_type == \"current\":\n",
        "        data = self.omega_df\n",
        "      elif items_type == \"tag\":\n",
        "        data = self.omega_tag_df\n",
        "\n",
        "\n",
        "      # if items_type == \"current\":\n",
        "      #   data =  self._items_to_frame(self.omega,self.E_s, data_name=\"Omega\")\n",
        "      # elif items_type == \"tag\":\n",
        "      #   data =  self._items_to_frame(self.omega_tag, self.E_s_tag, ord('A') + len(self.E_s),\n",
        "      #                                data_name=\"Omega_tag\")\n",
        "      if slate_id == -1:\n",
        "        return data\n",
        "      else:\n",
        "        return data.loc[data.slate_id == slate_id]\n",
        "\n",
        "\n",
        "    def generate_datasets(self, slate_id=-1):\n",
        "      self.Counter = self.Counter + 1\n",
        "      data = pd.DataFrame(self.omega.T).reset_index()\n",
        "\n",
        "      if len(data) < self.observations_per_user:\n",
        "        data['user_id'] = np.zeros(len(data))\n",
        "        data['slate_id'] = np.zeros(len(data))\n",
        "        # data['name'] = #data['index'].apply(lambda x: chr(ord('A')+x))\n",
        "        data['name'] = 'itm_' + data['item_id'].astype(str)\n",
        "        data['rational_user_val'] = self.omega.T@\\\n",
        "                                    self.user_model.rational_utility_weights\n",
        "        # self.top_5 = data.rational_user_val.argsort()[-5:][::-1]\n",
        "        self.top_5 = data.rational_user_val.sort_values(ascending=False).iloc[:5].index\n",
        "        print(self.top_5)\n",
        "        data['top_5'] = data['index'].apply(lambda x: x.index in self.top_5)\n",
        "        data['perceived_val'] = np.nan\n",
        "        data.loc[self.top_5, ['perceived_val']] = self.user_model(data.loc[self.top_5, [0,1]].values)\n",
        "        res = self._choice(data)\n",
        "\n",
        "      else:\n",
        "        # if slate_id != -1:\n",
        "        res = self.generate_slate_data_set(slate_id)\n",
        "\n",
        "      return res\n",
        "\n",
        "    def _choice(self, data, chosen='chosen'):\n",
        "        # dummies = pd.get_dummies(data.index)\n",
        "        # for name, group in grouped:\n",
        "        self.chosen = data['perceived_val'].astype(float).idxmax()\n",
        "        # data[chosen] = dummies.loc[data['perceived_val'].astype(float).idxmax(), :]\n",
        "        data[chosen] = (data['perceived_val'] == data['perceived_val'].max()).astype(int)\n",
        "        return data\n",
        "\n",
        "    def add_item(self, item_id):\n",
        "      assert (self.omega_tag_df.item_id==item_id).any(), f'Item {item_id} not in omega_tag'\n",
        "      assert (self.omega_df.item_id!=item_id).all(), f'Item {item_id} already in omega'\n",
        "      item = self.omega_tag_df.loc[self.omega_tag_df[\"item_id\"] == item_id].copy()\n",
        "      self.omega_df = pd.concat([\n",
        "          self.omega_df,\n",
        "          item,\n",
        "      ])\n",
        "\n",
        "      self.omega_df = self.omega_df.set_index(['item_id']).reset_index()\n",
        "\n",
        "    def drop_item(self, item_id):\n",
        "      assert (self.omega_df.item_id==item_id).any(), f'Item {item_id} not in omega'\n",
        "      # item_slate = self.omega_df.loc[self.omega_df.item_id == item_id].slate_id.iloc[0]\n",
        "      # item_index = self.omega_df.loc[self.omega_df.item_id == item_id].index\n",
        "      # self.omega_df.drop(index = item_id, inplace=True)\n",
        "      self.omega_df = self.omega_df.query('item_id != @item_id')\n",
        "\n",
        "    def top_5_idx(self, rational_user_val):\n",
        "      return rational_user_val.sort_values(ascending=False).iloc[:5].index\n"
      ],
      "metadata": {
        "id": "lu5DuUQDP0-a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train Context Environment\n",
        "\n",
        "class TrainContextChoiceEnvironment(DiscreteChoiceEnvironment):\n",
        "    \"\"\"\n",
        "    Dataset generator for binary choice with decision noise\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 observations_per_user=500,\n",
        "                 num_items=7,\n",
        "                 num_features=5):\n",
        "\n",
        "        self.user_models = {\n",
        "            'Attraction' : AttractionUserModel( np.arange(num_features),100),\n",
        "            'Compromise' : CompromiseUserModel(np.arange(num_features), 100),\n",
        "            'Similarity' : SimilarityUserModel(np.arange(num_features), 100),\n",
        "            'Rational' : RationalUserModel(np.arange(num_features)),\n",
        "            }\n",
        "\n",
        "        self.observations_per_user = observations_per_user\n",
        "        self.items_per_slate = num_items\n",
        "        self.n_features = num_features\n",
        "        self._generate_user_item_attributes(1)\n",
        "\n",
        "    def generate_datasets(self, num_features=5, num_items=7):\n",
        "\n",
        "          # df_train, df_test = list(), list()\n",
        "          # num_slates = self.omega_df.slate_id.nunique()\n",
        "          # train_slates = int(0.8*num_slates)\n",
        "\n",
        "          # for slate in range(train_slates):\n",
        "          #   df_train.append(self.generate_slate_data_set(slate))\n",
        "\n",
        "          # for slate in range(train_slates, num_slates):\n",
        "          #   df_test.append(self.generate_slate_data_set(slate))\n",
        "          # train_data = pd.concat(df_train).drop(columns=['name', 'index',])\n",
        "          # test_data = pd.concat(df_test)\n",
        "\n",
        "          # train_label = train_data['chosen']\n",
        "          # test_label = test_data['chosen']\n",
        "          self.items_per_slate = num_items\n",
        "          self.num_features = num_features\n",
        "\n",
        "          train_slates = int(0.8*self.observations_per_user)\n",
        "          train_data, y_train = self._generate_choice_dataset(num_features=num_features,\n",
        "                                                     num_slates=train_slates,\n",
        "                                                      num_items=num_items)\n",
        "\n",
        "          test_slates = self.observations_per_user - train_slates\n",
        "          test_data, y_test = self._generate_choice_dataset(num_features=num_features,\n",
        "                                                    num_slates=test_slates,\n",
        "                                                    num_items=num_items)\n",
        "\n",
        "\n",
        "\n",
        "          return train_data, test_data, y_train, y_test\n",
        "\n",
        "\n",
        "    def _choice(self, data):\n",
        "        dummies = pd.get_dummies(range(len(data)))\n",
        "        chosen = dummies[data.astype(float).argmax()]\n",
        "        return chosen\n",
        "\n",
        "    def _generate_choice_dataset(self, num_features=5, num_slates=500, num_items=7):\n",
        "        \"\"\"\n",
        "        Generate choice dataset, formatted as pandas dataframe.\n",
        "        \"\"\"\n",
        "        _, items = self._generate_user_item_attributes(0)\n",
        "\n",
        "\n",
        "        y_train = {name:[] for name,user in self.user_models.items()}\n",
        "        train = list()\n",
        "        for i in range(num_slates):\n",
        "            train.append(np.hstack(\n",
        "                      [np.ones((num_items, 1))*i, # slate_id\n",
        "                      np.random.normal(size=(num_items,num_features)), # data\n",
        "                                                    ]))\n",
        "            for name, user in self.user_models.items():\n",
        "              y_train[name].append(self._choice(user(train[-1][:,1:])))\n",
        "\n",
        "        feature_names = [f'x_{i}' for i in range(num_features)]\n",
        "        col_names = ['slate_id'] + feature_names\n",
        "        train_df = pd.DataFrame(np.vstack(train),\n",
        "                                columns=col_names)\n",
        "\n",
        "        for name, choices in y_train.items():\n",
        "          train_df[name] = np.hstack(choices)\n",
        "\n",
        "        train_data = train_df[col_names]#.drop(columns=['slate_id'])\n",
        "        y = train_df[list(y_train.keys()) + ['slate_id']]\n",
        "        return train_data, y\n",
        "\n",
        "    def mean_welfare(self, X):\n",
        "      return (X@np.arange(self.num_features)).mean()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# enV2 = TrainContextChoiceEnvironment(num_features=5, num_items=7)\n",
        "# enV2.generate_datasets(num_features=5, num_items=7)\n",
        "\n",
        "# add slate id to label, see which entry is value before doing so"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wEiPh6v9awBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n88hPyADw5G-"
      },
      "source": [
        "# Task 1: Engineering Choice Sets\n",
        "\n",
        "In this section, we build on the framework introduced in $HW2$ and construct sets of available items that cause (non-rational) users to choose items that are bad for them (i.e., have suboptimal value), but good for the system. In particular, users in this task will be susceptible to the *Attraction* context effect, and the way you construct the set of items should make use of this knowledge.\n",
        "\n",
        "#### Here is a **reminder** for $HW2$ settings:\n",
        "\n",
        "----------------------------------------\n",
        "\n",
        "**Recommendation procedure:**\n",
        "1. The collection of available items is the *ground set* $\\Omega=\\{x_1,...,x_n\\}$ ($n$ may be different in different parts of this task). Each item $x \\in s$ is described by two features, $x=(x_1, x_2)$.\n",
        "2. There is a single user whose (true) value function is $v(x)=\\alpha^\\top x$. I.e., if the user chooses item $x_i$, then she receives $\\alpha_1\\cdot x_{i1} + \\alpha_2\\cdot x_{i2}$ utility from this choice. **The value vector $\\alpha$ is known to the system**.\n",
        "3. System also benefits from user choices. If the user chooses item $x_i$, then the system receives $e_i$ utility. The values $e_i$ are predetermined, known to the system, and do not depend on features.\n",
        "4. The system recommends to the user the top-5 items $x\\in \\Omega$ having highest value. We will call this the *choice set*, denoted $s \\in \\Omega$.\n",
        "5. The user chooses exactly one item $x \\in s$. This is the item with highest *perceived value*, as determined by the attraction effect:\n",
        "$$\n",
        "  \\tilde{v}(x|s) = \\alpha^\\top x + \\mathtt{att}(x|s)\n",
        "$$\n",
        "where $\\mathtt{att}$ is as was defined in class. We will denote the chosen item by $y = \\mathtt{argmax}_{x \\in s} \\tilde{v}(x|s)$.\n",
        "6. User receives utility $v(y)$, and system receives utility $e_y$.\n",
        "\n",
        "----------------------------------------\n",
        "\n",
        "In the above description, the system recommends in a way that is optimal to users. In this task, *you are an agent of the system*, and your goal is to maximize the system's utility.\n",
        "\n",
        "Of course, you cannot simply force the user to choose a certain item, nor can you change the recommendation procedure. The only thing you are allowed to do is to modify $\\Omega$ by adding one additional item from a different set of items, $\\Omega'$. Once $\\Omega$ is modified (i.e., includes one additional item), the recommendation procedure and user choice behavior is as described above.\n",
        "Hence, your goal is to (manually) choose $x \\in \\Omega$ such that the choice $y$ derived from a top-5 recommended set $s$ based on the collection of items $\\Omega \\cup \\{x\\}$ will results in high system utility $e_y$ (and possibly with lower utility $v(y)$ to the user).\n",
        "\n",
        "As you will see, items in  $\\Omega'$ actually have lower system values $e_i$ than items in $\\Omega$ ($\\forall e \\in E_S, e' \\in E_S':  e > e'$). Therefore, the item you add will serve as a *decoy*: these serve to modify the preceived values of items in $s$, in a way that utilizes the attraction effect to affect choice behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**In this section, you will write a simple algorithm that automatically finds the optimal item in $\\Omega'$ to add to $\\Omega$ in order to maximize system utility.**\n",
        "\n"
      ],
      "metadata": {
        "id": "P_hmjC2K_qJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Warm up\n",
        "\n",
        "Here we explore with useful functions of ```ContextChoiceEnvironment```.\n",
        "\n",
        "Note that user parameters are:\n",
        "\\begin{align}\n",
        "\\alpha_1 = 1, \\alpha_2 = 9\n",
        "\\end{align}\n",
        "\n"
      ],
      "metadata": {
        "id": "CaXWuJlT_BUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = ContextChoiceEnvironment()"
      ],
      "metadata": {
        "id": "wPW5i4PLBBQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use ```inspect_data``` to view $Ω$ and $Ω'$ (using \"current\" and \"tag\" inputs strings). Note that this time the data contains multiple slates\n",
        "\n"
      ],
      "metadata": {
        "id": "Nosb0jvXBmLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.inspect_data(\"current\")"
      ],
      "metadata": {
        "id": "tyQ9Al4iFvKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.inspect_data(\"tag\")"
      ],
      "metadata": {
        "id": "oH6VUnu0F1xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following method are used to add and pop items from $Ω$:\n",
        "*  Method ```env.add_item(item_id=i)``` is used to add an item from $Ω'$ to $Ω$ according to its index at $Ω'$ (as in $HW2$).\n",
        "\n",
        "*   Method ```env.drop_item(item_id=i)``` is used to drop item i from $Ω$.\n",
        "\n",
        "Both return none.\n",
        "\n",
        "Use these to add item with item_id 750 from $Ω'$'s slate_id==0 and add it to $Ω$'s slate_id==0.\n",
        "Then remove this item from $Ω$'s slate_id==0.\n",
        "Print DataFrame at each stage using ```inspect_data``` fuction with ```slate_id=0```:\n"
      ],
      "metadata": {
        "id": "uppYAQXwJSbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "go1pbqX3LXlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "9IcoNv0iLrqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarlty to $HW2$, method ```env.generate_datasets``` generates a DataFrame indicating whether an item in $Ω$ is selected to Top 5 and displayed to the user, its precieved value, and the final choice by the user.\n",
        "Now that we work with multiple slates we will provide **slate_id** as input.\n",
        "\n",
        "Use ```generate_datasets``` to print such dataframe for slate 0:"
      ],
      "metadata": {
        "id": "Q5-irQKzNQGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "xIk5bHx_NQ1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment's method ```env.top_5_idx``` gets rational user values of a specific slate as input, and outputs the indices of the top 5 items. Those items will be displayed to the user.\n",
        "\n",
        "Use this method to print the indices of the items selected from $Ω$'s slate_id=0:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NnE0b9OqF4tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "2vMpD2iXImGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a procedure that checks for each item in $\\Omega'$ whether it would have been included in the top 5 if added to its respective slate.\n",
        "\n",
        "Output a DataFrame with `item_id` and a boolean column named `is_top_5`.(`True` will be included in top 5)\n"
      ],
      "metadata": {
        "id": "1rTsYERm5en-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "gEMsqg687UMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Automate Choice Set Selection\n",
        "\n",
        "### 1.2.1 Algorithm (Open Ended)\n",
        "\n",
        "Now - write a simple algorithm that automatically finds the optimal item in  Ω′  to add to  Ω  in order to maximize system utility. Note: it may decide not to add an item if there is no benefit to the system.\n",
        "\n",
        "In particular, your algorithm recieves as input:\n",
        "* Two sets of items, $\\Omega,\\Omega'$, where each is a 2D numpy array of sizes $(n,2)$ and $(n',2)$ ($n,n'$ can vary)\n",
        "* Corresponding system utilities $e_{\\Omega}, e_{\\Omega'}$, each a numpy array of sizes $n$ and $n'$\n",
        "\n",
        "The algorithm should output:\n",
        "* The index in $\\Omega'$ of the item you wish to add to $\\Omega$ per slate.\n",
        "* The utility of the system after adding this item.\n",
        "\n",
        "We will give you a collection of 50 example inputs to your algorithm (that is, 50 sets of $(\\Omega,\\Omega')$ pairs) with $n=15, n'=100$. Write code that applies your algorithm to each of these 50 inputs, and **prints the added items and their corresponding system utilities.**\n",
        "\n",
        "**Limitations**:\n",
        "You may call generate_datasets *up to 300 times* overall. We are looking for clever heuristics. Write efficient code!"
      ],
      "metadata": {
        "id": "TYNis0cJEdhG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggqta9VsizfP"
      },
      "source": [
        "**Bonus:** We will have a competition between submited algorithms. We will run your code on a fresh batch of inputs - the two teams achieving the highest system utility will get 5 bonus points for this exercise.\n",
        "\n",
        "**WORK ON THIS BONUS ONLY AFTER YOU'VE COMPLETED THE ENTIRE WORKSHOP.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y6IMXziyxcc"
      },
      "source": [
        "# Input - reset environment\n",
        "env = ContextChoiceEnvironment()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, calculate the originial system value from the items chosen by the user in Omega. Print it:"
      ],
      "metadata": {
        "id": "JBWVHLcAngD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "0QE80yiJngXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each use of generate_dataset increase envriment counter"
      ],
      "metadata": {
        "id": "Q7RO3MXFsWay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.Counter"
      ],
      "metadata": {
        "id": "53_qTQ9BsQX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your own algorithm and print the new system value per slate.\n",
        "Note that you *may* use $\\Omega,\\Omega'$ dataframes as inputs (retable from `inspect_data`, `generate_datasets` etc).  "
      ],
      "metadata": {
        "id": "-eEscPWSngij"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YveP6g8OjcUl"
      },
      "source": [
        "env.Counter = 0\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the overall system value (sum of all slates)"
      ],
      "metadata": {
        "id": "JJbbofInmDOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "Y8GuArpOuFWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j6aTCLNyzju"
      },
      "source": [
        "1.2.2 **Explain your algorithm.**\n",
        "\n",
        "What is the basic principle underlying your implementation? Explain how your approach utilizes the attraction effect.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Answer: ...\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "d0ZpMJ2rbKU3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeSkJyqHH2_8"
      },
      "source": [
        "Given that you could not evalute all items in in $ֿ\\Omega'$ (restriction) - how did you prioritize evaluations?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Answer: ...\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "rGjd48CKbL6w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXJn99fMRiLP"
      },
      "source": [
        "# Task 2: Prediction and IIA\n",
        "In this exercise you will examine the sensitivity of different predictive models to behavioral violations of IIA. We will use behavioral choice models to generate choice behavior that deviates from IIA in different ways. Then, we will evaluate the performance of predictive models trained on generated choice data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF2u7YAcS012"
      },
      "source": [
        "#### Behavioral Bias\n",
        "You will explore the model preformance for **Rational** users, but also for users who are subjected to following behavioral biases:\n",
        "**Similarity**, **Compromise**, and **Attraction**.\n",
        "In this task you will repeat the same learning pipeline for each of these users, and compare results.\n",
        "\n",
        "We adivse you refer to the context effect slides refersh you memory if needed:)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective utility is determined by rational user parameters $\\beta$:  $\\beta^T X$.\n",
        "\n",
        "Precived utility is a combination of objective utility and specific context effect:  $\\beta^T X + \\alpha \\cdot effect$\n",
        "\n",
        "All users share the paramters but differ in the manifested behavioral context effect."
      ],
      "metadata": {
        "id": "p9b_CXi0Vv5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Enviroment\n",
        "Here we shall work with a new enviroment - ```TrainContextChoiceEnvironment```, which provides datasets, including items with different features, slate_id, along with choices made by the user above."
      ],
      "metadata": {
        "id": "OHkCxaD-JJYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env2 = TrainContextChoiceEnvironment()"
      ],
      "metadata": {
        "id": "WJsJj_Gc500C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method ```env2.generate_dataset``` generates train and test datasets along with their corresponding labels. It recives *num_futures* (# features per item) and *num_item* (# of items per slate. Outputs DaraFrame of the form: ```train_data, test_data, y_train, y_test```. Each output DataFrame contains *slate_id*.\n",
        "\n",
        "Create an environment object with 7 items per slate and 5 features for each item. Note the each choice column is a one-hot repersentation of the item selected per slate."
      ],
      "metadata": {
        "id": "ULFVAuAWWnSR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xd6y-18fpWn"
      },
      "source": [
        " # generate data\n",
        "\n",
        "X_train, X_test, y_train, y_test = env2.generate_datasets(num_features=5, num_items=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect ```y_train```. Which items were selected by Rational and Compromise users from slate 0 in the train set?\n",
        "Print a slice of train data DataFrame that presents their features."
      ],
      "metadata": {
        "id": "7blSzIdlZN83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "m3Z2L-Rrb2Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Another ```TrainContextChoiceEnvironment```'s method is ```mean_welfare``` which gets as input features DataFrame or matrix [#items, #features] and calculates the mean welfare.\n",
        "\n",
        "Print the mean welfare of the entire trainset and the mean welfare of the trainset for items selected by Rational users.\n",
        "\n"
      ],
      "metadata": {
        "id": "cjzDIndZb2z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "vN2m2q7ijwP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "Usvnp0hKINvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb2n9XdUzeCY"
      },
      "source": [
        "## 2.2 Train predictive models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDs0F1n6H3dk"
      },
      "source": [
        "In this section we will compare the performance of two predictive models:\n",
        "1. Logistic Regression, and\n",
        "2. the pairwise ranker you implemented at home\n",
        "(as was announced, you may choose the school-solution pairwise ranker instead, but we encourage you to try and work with your own implementation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5nlL3ElX7Rf"
      },
      "source": [
        "2.2.1 For each user type (do this in a for loop over user types):\n",
        "* Train a logistic regression model, and evaluate its test performance using accuracy and precision functions.\n",
        "* Use the inputs generated above.\n",
        "\n",
        "You are encouraged to save the two preformance measures for each user type in a dictionary. This will be helpful in the next sections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGQVFsSrYP0M"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwhRiQlNXeM4"
      },
      "source": [
        "2.2.2 Train your pairwise ranker. Repeat the above procedure.\n",
        "\n",
        "(make sure you use different named variables for performance measures, so they do not overwrite the Logistic regression results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ranker\n",
        "\n",
        "# ## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "-yhHObw4DnAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit & Predict\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "7iLneuL_r0_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVhCJrEePuva"
      },
      "source": [
        "2.2.3 Plot your results - compare logistic regression and the pairwise ranker.\n",
        "\n",
        "Plot a bar graph that compares the performance of each method accorss the differet behavioral models.\n",
        "* Genarate 2 figures, one for each performance measure: accuracy and precision.\n",
        "* For each performance measure, generate a bar plot with 4 bar groups (one per user model), with each group having two bars (one per method).\n",
        "* Remember to include: title, axis labels, and a lengend.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "vBHda0XHERAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-U09Fmoak7U"
      },
      "source": [
        "# Precision\n",
        "\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the following discussion, you may refer to a pairwise ranker reminder in [course website](https://gr.cs.technion.ac.il/wc/handouts.cgi?e0iyxQZd2B3ZJyP)."
      ],
      "metadata": {
        "id": "OL8sZiJ2i0CX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-4S1xyAKoM3"
      },
      "source": [
        "2.2.4 Explain your results: What is the difference between accuracy to precision results? why is that?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Answer: ...\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "bEvjzyCYbERW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per user behavior - what determines differences? What determines similarites? Would you expect these results to hold in general?"
      ],
      "metadata": {
        "id": "-YHaMpNcOb8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Answer: ...\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-aIytG8wbCdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.3 Your model\n",
        "\n",
        "Now it is up to you to improve preformance: implement a model that **leverages behavioral context effects** with 3 features, and 10 items per slate.\n",
        "Plot Accuracy and Precision per user model for baselines (from the previous section) and compare it to the newly achieved results.\n",
        "\n",
        "\n",
        "Pass criteria: improve results for at least two users."
      ],
      "metadata": {
        "id": "ZyWzZys4Rd0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run baselines\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "4_NJjSveiJfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your model\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "vROKaYphUyZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "MUnpvLh3U-k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "\n",
        "## YOUR SOLUTION"
      ],
      "metadata": {
        "id": "6rNPOZ-NJQDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain what is main idea of behine this model? What enbles it to capture context effects?"
      ],
      "metadata": {
        "id": "3E2N7P6BU2x5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Answer: ...\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "xeun0aPla3oJ"
      }
    }
  ]
}